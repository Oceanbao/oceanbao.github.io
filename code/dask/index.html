<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<meta name="description" content="Ocean on GitHub.">

<meta name="twitter:card" content="summary">
<meta name="twitter:domain" content="https://oceanbao.github.io/">

<meta name="twitter:image" content="https://oceanbao.github.io/tn.png">
<meta name="twitter:title" property="og:title" itemprop="title name" content="Ocean Ode">
<meta name="twitter:description" property="og:description" itemprop="description" content="Ocean on GitHub.">
<meta name="og:type" content="website">
<meta name="og:url" content="https://oceanbao.github.io/">
<meta name="og:image" itemprop="image primaryImageOfPage" content="https://oceanbao.github.io/tn.png">

<link rel="shortcut icon" href="https://oceanbao.github.io/oceanicon.jpg" id="favicon">
<link rel="stylesheet" href="https://oceanbao.github.io/css/style.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">


    

    
    
    
    <title>
        
        DASK
        
    </title>
</head>

<body>

    <div class="wrap">
        <div class="section" id="title">DASK</div>
        <aside>
            <nav id="TableOfContents">
<ul>
<li><a href="#toc">TOC</a>
<ul>
<li><a href="#tom-augspurger-talks-tom"><a href="#tom">Tom Augspurger Talks</a></a></li>
<li><a href="#official-dask-distributed-kubernetes-official"><a href="#official">Official: Dask.distributed &amp; Kubernetes</a></a></li>
<li><a href="#matthew-rocklin-talks-rocklin"><a href="#rocklin">Matthew Rocklin Talks</a></a></li>
<li><a href="#jim-crist-talks-jim"><a href="#jim">Jim Crist Talks</a></a></li>
<li><a href="#long-scipy-tutorial-long"><a href="#long">Long SciPy Tutorial</a></a></li>
<li><a href="#datacamp-datacamp"><a href="#datacamp">DataCamp</a></a></li>
<li><a href="#streamz-streamz"><a href="#streamz">Streamz</a></a></li>
<li><a href="#reference-tom-augspurger-github-https-github-com-tomaugspurger-a-id-tom-a">Reference <a href="https://github.com/TomAugspurger">Tom Augspurger Github</a> <a id="tom"></a></a>
<ul>
<li><a href="#examples-https-github-com-dask-dask-examples"><a href="https://github.com/dask/dask-examples">Examples</a></a></li>
</ul></li>
</ul></li>
<li><a href="#scaling-pains">Scaling Pains</a>
<ul>
<li><a href="#example-of-dask-ml">Example of dask_ml</a></li>
</ul></li>
<li><a href="#official-doc-dask-distributed-kubernetes-a-id-official-a">Official Doc Dask.distributed &amp; Kubernetes <a id="official"></a></a>
<ul>
<li><a href="#quickstart-official-doc">QuickStart Official Doc</a>
<ul>
<li>
<ul>
<li><a href="#restart-cluter-scheduler-at-error">Restart Cluter/Scheduler at error</a></li>
</ul></li>
<li><a href="#map-and-submit">Map and Submit</a></li>
<li><a href="#gather">Gather</a></li>
<li><a href="#setup-network">Setup Network</a>
<ul>
<li><a href="#note-both-scheduler-worker-neet-to-accept-tcp-connections-default-port-8786-and-random-for-workers-if-firewall-need-port-worker-port-keywords">NOTE both scheduler/worker neet to accept TCP connections, default port 8786 and random for workers - if firewall need <code>--port -worker-port</code> keywords</a></li>
</ul></li>
<li><a href="#custom-init">Custom INIT</a></li>
<li><a href="#client-primary-entry-point-overall">Client (Primary Entry Point overall)</a>
<ul>
<li><a href="#concurrent-futures">Concurrent.futures</a></li>
<li><a href="#dask-parent-lib-auto-parallel-algo-on-dsets">Dask (Parent lib, auto-parallel algo on dsets)</a></li>
<li><a href="#dask-normal-compute-synchronous-blocking-interpreter-till-complete-dask-distributed-allows-asynchronous-trigging-ops-in-background-and-persist-in-memo-while-taking-on-other-works-typically-handled-with-client-persist-for-large-result-set-and-client-compute-smaller-result">Dask normal <code>.compute()</code> SYNCHRONOUS<code>, blocking interpreter till complete -</code>dask.distributed<code>allows ASYNCHRONOUS trigging ops in background and persist in MEMO while taking on other works - typically handled with</code>Client.persist<code>for large result set and</code>Client.compute` smaller result</a></li>
<li><a href="#pure-func-by-default">Pure Func by Default</a></li>
<li><a href="#tornado-coroutines">Tornado Coroutines</a></li>
</ul></li>
<li><a href="#api-see-doc">API see Doc</a></li>
<li><a href="#q-a">Q&amp;A</a></li>
<li><a href="#diagnosis">Diagnosis</a>
<ul>
<li><a href="#task-on-and-off-times">Task On and Off Times</a></li>
<li><a href="#statistical-profiling">Statistical Profiling</a></li>
</ul></li>
<li><a href="#efficiency">Efficiency</a>
<ul>
<li><a href="#leave-data-on-cluster">Leave data on cluster</a></li>
<li><a href="#user-larger-tasks">User larger tasks</a></li>
<li><a href="#scheduler-adds-aout-1ms-overhead-per-task-or-future-obj-slow-if-billions-of-tasks-if-func-run-faster-than-100ms-then-might-not-see-any-speedup-from-using-distributed-computing">scheduler adds aout 1ms overhead per task or Future obj, slow if billions of tasks - if func run faster than 100ms then might not see any speedup from using distributed computing !!</a></li>
<li><a href="#adjust-betweeen-threads-and-processes">Adjust betweeen Threads and Processes!!!</a></li>
<li><a href="#dont-go-distributed">DONT GO Distributed</a></li>
</ul></li>
<li><a href="#limit">LIMIT</a>
<ul>
<li><a href="#performance">Performance</a></li>
<li><a href="#workers-are-just-python-processes-inheriting-all-pros-and-cons-of-python-not-bound-or-limit-in-any-way-production-may-wish-to-run-dask-workers-within-containers">Workers are just Python processes, inheriting all pros and cons of Python - Not bound or limit in any way, PRODUCTION may wish to run dask-workers within CONTAINERS !!</a></li>
<li><a href="#assumptions-on-func-and-data">Assumptions on FUNC and DATA</a></li>
</ul></li>
<li><a href="#security">Security</a></li>
<li><a href="#data-locality">Data Locality</a>
<ul>
<li><a href="#user-control">User Control</a></li>
<li><a href="#worker-with-compute-persist">Worker with Compute/Persist</a></li>
</ul></li>
<li><a href="#managing-computation">Managing Computation</a>
<ul>
<li><a href="#dask-collections-to-concrete-values">Dask Collections to Concrete Values</a></li>
<li><a href="#dask-collection-to-futures">Dask Collection to Futures</a></li>
<li><a href="#concrete-value-to-futures">Concrete Value to Futures</a></li>
<li><a href="#futures-to-concrete-values">Futures to Concrete Values</a></li>
<li><a href="#futures-to-dask-collections">Futures to Dask Collections</a></li>
</ul></li>
<li><a href="#managing-mem">Managing MEM</a>
<ul>
<li><a href="#creating-futures">Creating Futures</a></li>
<li><a href="#persisting-collections">Persisting Collections</a></li>
<li><a href="#difference-with-dask-compute">Difference with dask.compute</a></li>
<li><a href="#clearing-data">Clearing data</a></li>
<li><a href="#hard-clearing-ddata">Hard Clearing ddata</a></li>
<li><a href="#resilience">Resilience</a></li>
</ul></li>
<li><a href="#advanced-techniques">Advanced techniques</a></li>
</ul></li>
</ul></li>
<li><a href="#matthew-rocklin-talks-a-id-rocklin-a">Matthew Rocklin Talks <a id="rocklin"></a></a>
<ul>
<li><a href="#dask">DASK</a>
<ul>
<li><a href="#single-machine-scheduler">Single Machine Scheduler</a></li>
<li><a href="#distributed-scheduler">Distributed Scheduler</a></li>
<li><a href="#concurrent-futures-pep-3148">Concurrent.futures (PEP 3148)</a></li>
<li><a href="#async-await">Async/Await</a></li>
<li><a href="#dask-distributed-scheduler-even-on-single-machine"><code>dask.distributed</code> Scheduler (Even on Single Machine)</a></li>
<li><a href="#customised-programme-with-dask-example">Customised Programme with Dask (Example)</a>
<ul>
<li><a href="#futures-api">Futures API</a></li>
<li><a href="#track-dependencies-on-the-fly">Track dependencies ON-THE-FLY</a></li>
<li><a href="#convenient-methods-exist-to-support-asynchronous-workloads">Convenient methods exist to support asynchronous workloads</a></li>
<li><a href="#worker-starts-client-scheduler">Worker Starts Client/Scheduler!</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#jim-crist-talks-a-id-jim-a">Jim Crist Talks <a id="jim"></a></a>
<ul>
<li>
<ul>
<li><a href="#parallel-numpy-and-pandas-through-task-scheduling">Parallel NumPy and Pandas through Task Scheduling</a></li>
<li><a href="#dataframes-on-cluster">DataFrames on Cluster</a>
<ul>
<li><a href="#parallelise-normal-python-code">Parallelise Normal Python code</a></li>
</ul></li>
</ul></li>
<li><a href="#long-scipy-tutorial-2017-a-id-long-a">Long SciPy Tutorial 2017 <a id="long"></a></a>
<ul>
<li><a href="#dask-dataframe">Dask.dataframe</a>
<ul>
<li><a href="#client-default-creating-one-worker-per-core">Client() default-creating ONE WORKER PER CORE</a></li>
</ul></li>
<li><a href="#cluster-creation-cluster-specific-dask-cli-available-es2-kubernetes">Cluster Creation: Cluster-specific DASK-CLI available (ES2, Kubernetes)</a>
<ul>
<li><a href="#dask-worker-schedulerip-will-default-single-worker-process-with-threads-as-cores-available">dask-worker <code>schedulerIP</code> will default SINGLE WORKER PROCESS with #THREADS AS CORES AVAILABLE</a></li>
</ul></li>
<li><a href="#accessing-same-dataset-among-workers">ACCESSING SAME DATASET among WORKERS</a>
<ul>
<li><a href="#however-if-setting-date-column-as-index-then-faster-calling-set-index-persist-new-set-of-df-partitions-stored-in-mem-sorted-along-index-col-dask-shuffles-data-by-date-set-index-per-partition-store-in-cluster-mem">HOWEVER: if setting <code>Date</code> column as index then FASTER - calling <code>set_index</code> + <code>persist</code> =&gt; new set of DF partitions stored IN-MEM, sorted along index col - DASK shuffles data by date, set index per partition, store in cluster-MEM</a></li>
</ul></li>
<li><a href="#relatively-costly-but-gain-certain-query-speed">Relatively COSTLY - but gain certain query-speed</a></li>
<li><a href="#time-series-index-datetimeindex-pandas-are-supported">TIME SERIES INDEX: <code>DatetimeIndex</code> pandas are supported</a></li>
</ul></li>
<li><a href="#distributed-features">DISTRIBUTED FEATURES</a>
<ul>
<li>
<ul>
<li><a href="#note-difference-total-compute-completes-immediately">NOTE difference: total.compute() completes immediately</a></li>
</ul></li>
</ul></li>
<li><a href="#two-easy-ways-to-skl-dask">Two Easy Ways to SKL+DASK</a>
<ul>
<li><a href="#joblib">Joblib</a></li>
<li><a href="#distributed-joblib">Distributed Joblib</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#dask-learn-pipeline-and-gridsearch">Dask-Learn Pipeline and GridSearch</a></li>
<li><a href="#better">Better</a></li>
</ul></li>
<li><a href="#convex-optimisation-algo-with-dask">Convex Optimisation Algo with Dask</a>
<ul>
<li><a href="#prototyping-algo-in-dask">Prototyping Algo in Dask</a></li>
<li><a href="#example-fitting-large-lm-using-array-parallelism-and-customised-from-dask">Example - fitting large LM using array parallelism and customised from Dask</a></li>
<li><a href="#array-programming">Array Programming</a></li>
</ul></li>
</ul></li>
<li><a href="#datacamp-a-id-datacamp-a">DataCamp <a id="datacamp"></a></a></li>
<li><a href="#working-with-big-data">Working with BIG DATA</a>
<ul>
<li><a href="#time-and-bit">Time and Bit</a></li>
<li><a href="#querying-python-interpreter-s-memory-usage">Querying Python interpreter&rsquo;s Memory Usage</a></li>
<li><a href="#think-data-in-chunks">Think data in CHUNKs</a>
<ul>
<li><a href="#managing-data-with-generators">Managing Data with Generators</a></li>
</ul></li>
<li><a href="#generator-for-delaying-computing-and-saving-memory-usage-dask-to-simplify">Generator for delaying computing and saving memory usage: DASK to simplify</a></li>
<li><a href="#visualising-complex-dependency-loops-computations">Visualising complex dependency loops / computations</a></li>
<li><a href="#dask-arrays-and-chunking">Dask Arrays and Chunking</a>
<ul>
<li><a href="#dask-scheduler-auto-assign-multiple-processors-threads-concurrently-available">Dask scheduler auto-assign multiple processors/threads concurrently available !</a></li>
</ul></li>
<li><a href="#multi-dimension-array-wrangling-similar-to-numpy">Multi-Dimension Array Wrangling ~ similar to Numpy</a>
<ul>
<li><a href="#wrangling-with-arrays">Wrangling with Arrays</a>
<ul>
<li><a href="#sample-code">Sample Code</a></li>
</ul></li>
</ul></li>
<li><a href="#dask-dataframe-pandas-df">Dask DataFrame ~ Pandas DF</a></li>
<li><a href="#timing-dask-df-loading-and-computation">Timing Dask DF Loading and Computation</a>
<ul>
<li>
<ul>
<li><a href="#decision-to-both-largely-depends-on-whehter">Decision to both largely depends on whehter</a></li>
<li><a href="#example-analysing-full-year-taxi-tipping">Example analysing full-year taxi tipping</a></li>
</ul></li>
</ul></li>
<li><a href="#dask-bag-and-globbing">Dask Bag and Globbing</a></li>
<li><a href="#all-together-detailed-analysis">All together Detailed Analysis</a></li>
</ul></li>
<li><a href="#streamz-streaming-data-analysis-pythonic-with-dask-a-id-streamz-a">Streamz - Streaming Data Analysis Pythonic with Dask <a id="streamz"></a></a>
<ul>
<li>
<ul>
<li><a href="#code-to-create-random-json-data">Code to create random JSON data</a></li>
<li><a href="#basic-streams-and-map">Basic Streams and Map</a></li>
</ul></li>
<li><a href="#async-computation">Async Computation</a>
<ul>
<li><a href="#mock-continous-updates">Mock Continous updates</a></li>
<li><a href="#accumulators">Accumulators</a></li>
</ul></li>
</ul></li>
<li><a href="#streaming-bokeh-server">Streaming + Bokeh Server</a>
<ul>
<li>
<ul>
<li><a href="#launch-bokeh-servers-from-notebook">Launch Bokeh Servers from Notebook</a></li>
<li><a href="#live-updates">Live Updates</a></li>
<li><a href="#real-example-dask-s-dashboard">Real example - Dask&rsquo;s dashboard</a></li>
</ul></li>
<li><a href="#streaming-dataframes">Streaming Dataframes</a></li>
</ul></li>
</ul>
</nav>
        </aside>
        <div class="section" id="content">

<h1 id="toc">TOC</h1>

<ol>
<li><h2 id="tom-augspurger-talks-tom"><a href="#tom">Tom Augspurger Talks</a></h2></li>

<li><h2 id="official-dask-distributed-kubernetes-official"><a href="#official">Official: Dask.distributed &amp; Kubernetes</a></h2></li>

<li><h2 id="matthew-rocklin-talks-rocklin"><a href="#rocklin">Matthew Rocklin Talks</a></h2></li>

<li><h2 id="jim-crist-talks-jim"><a href="#jim">Jim Crist Talks</a></h2></li>

<li><h2 id="long-scipy-tutorial-long"><a href="#long">Long SciPy Tutorial</a></h2></li>

<li><h2 id="datacamp-datacamp"><a href="#datacamp">DataCamp</a></h2></li>

<li><h2 id="streamz-streamz"><a href="#streamz">Streamz</a></h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> IPython.core.interactiveshell <span style="color:#f92672">import</span> InteractiveShell
InteractiveShell<span style="color:#f92672">.</span>ast_node_interactivity <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;all&#34;</span>

<span style="color:#f92672">%</span>config InlineBackend<span style="color:#f92672">.</span>figure_format <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span>


<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt</code></pre></div></li>
</ol>

<h2 id="reference-tom-augspurger-github-https-github-com-tomaugspurger-a-id-tom-a">Reference <a href="https://github.com/TomAugspurger">Tom Augspurger Github</a> <a id="tom"></a></h2>

<ul>
<li><a href="https://tomaugspurger.github.io/sklearn-dask-tabular.html">Tabular Data in SKL and DaskML</a></li>
<li><a href="https://mybinder.org/v2/gh/dask/dask-examples/master?filepath=machine-learning%2Ftpot.ipynb">TPOT with Dask</a></li>
</ul>

<h3 id="examples-https-github-com-dask-dask-examples"><a href="https://github.com/dask/dask-examples">Examples</a></h3>

<h1 id="scaling-pains">Scaling Pains</h1>

<ul>
<li>Model Complexity VS Data
<img src="https://image.slidesharecdn.com/scalable-ml-180514203801/95/scalable-machine-learning-with-dask-tom-augspurger-18-1024.jpg?cb=1526330748" alt="Scaling" /></li>
<li>Distributed SKL - using DASK to distribute computation on cluster (Large Model - Smaller Datasets)</li>
</ul>

<blockquote>
<p><strong>Single-Machine Parallelism with SKL</strong></p>

<ol>
<li>control CPU processors (<code>n_jobs=-1</code>)</li>
</ol>

<p><strong>Multi-Machine with Dask</strong></p>
</blockquote>

<ul>
<li><code>from sklearn.externals import joblib</code></li>
<li><code>import dask_ml.joblib</code></li>
<li><code>clf = RandomForestCalssifier(n_estimators=200, n_jobs=-1)</code></li>

<li><p><code>with joblib.parallel_backend(&quot;dask&quot;, scatter=[X,y]): clf.fit(X,y)</code></p></li>

<li><p>Caveats</p>

<ol>
<li>Data must fit RAM</li>
<li>Data shipped to each worker

<ul>
<li>Each parallel task expensive</li>
<li>Should be many parallel tasks</li>
</ul></li>
</ol></li>

<li><p>First: Must all data be used?</p></li>
</ul>

<blockquote>
<p><strong>Sampling may allow / plotting learning curve by data size to inspect improvement</strong></p>
</blockquote>

<ul>
<li><p>Second: Parallel Meta-estimators</p>

<ul>
<li>Train on subset</li>
<li>Predict for large dataset in parallel</li>
</ul></li>
</ul>

<blockquote>
<p>wrap data X with dask.dataframe then clf.predict(X)</p>
</blockquote>

<ul>
<li><p>Dask_ML on scalable, parallel algos (to dig) <a href="https://git.io/vAi7C">Example of Pipeline in SKL</a></p></li>

<li><p>Distributed System: Peer with systems like XGBoost or TensorFlow</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> dask_ml.xgboost <span style="color:#f92672">as</span> xgb
df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv()
booster <span style="color:#f92672">=</span> xgb<span style="color:#f92672">.</span>train(client, params, X, y)</code></pre></div></li>
</ul>

<h2 id="example-of-dask-ml">Example of dask_ml</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#reading the csv files</span>
<span style="color:#f92672">import</span> dask.dataframe <span style="color:#f92672">as</span> dd
df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;blackfriday_train.csv&#39;</span>)
test<span style="color:#f92672">=</span>dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;blackfriday_test.csv&#34;</span>)

<span style="color:#75715e">#having a look at the head of the dataset</span>
df<span style="color:#f92672">.</span>head()

<span style="color:#75715e">#finding the null values in the dataset</span>
df<span style="color:#f92672">.</span>isnull()<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>compute()

<span style="color:#75715e">#defining the data and target</span>
categorical_variables <span style="color:#f92672">=</span> df[[<span style="color:#e6db74">&#39;Gender&#39;</span>, <span style="color:#e6db74">&#39;Age&#39;</span>, <span style="color:#e6db74">&#39;Occupation&#39;</span>, <span style="color:#e6db74">&#39;City_Category&#39;</span>, <span style="color:#e6db74">&#39;Stay_In_Current_City_Years&#39;</span>, <span style="color:#e6db74">&#39;Marital_Status&#39;</span>]]
target <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Purchase&#39;</span>]

<span style="color:#75715e">#creating dummies for the categorical variables</span>
data <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>get_dummies(categorical_variables<span style="color:#f92672">.</span>categorize())<span style="color:#f92672">.</span>compute()

<span style="color:#75715e">#converting dataframe to array</span>
datanew<span style="color:#f92672">=</span>data<span style="color:#f92672">.</span>values

<span style="color:#75715e">#fit the model</span>
<span style="color:#f92672">from</span> dask_ml.linear_model <span style="color:#f92672">import</span> LinearRegression
lr <span style="color:#f92672">=</span> LinearRegression()
lr<span style="color:#f92672">.</span>fit(datanew, target)

<span style="color:#75715e">#preparing the test data</span>
test_categorical <span style="color:#f92672">=</span> test[[<span style="color:#e6db74">&#39;Gender&#39;</span>, <span style="color:#e6db74">&#39;Age&#39;</span>, <span style="color:#e6db74">&#39;Occupation&#39;</span>, <span style="color:#e6db74">&#39;City_Category&#39;</span>, <span style="color:#e6db74">&#39;Stay_In_Current_City_Years&#39;</span>, <span style="color:#e6db74">&#39;Marital_Status&#39;</span>]]
test_dummy <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>get_dummies(test_categorical<span style="color:#f92672">.</span>categorize())<span style="color:#f92672">.</span>compute()
testnew <span style="color:#f92672">=</span> test_dummy<span style="color:#f92672">.</span>values

<span style="color:#75715e">#predict on test and upload</span>
pred<span style="color:#f92672">=</span>lr<span style="color:#f92672">.</span>predict(testnew)


<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client
client <span style="color:#f92672">=</span> Client() <span style="color:#75715e"># start a local Dask client</span>

<span style="color:#f92672">import</span> dask_ml.joblib
<span style="color:#f92672">from</span> sklearn.externals.joblib <span style="color:#f92672">import</span> parallel_backend
<span style="color:#66d9ef">with</span> parallel_backend(<span style="color:#e6db74">&#39;dask&#39;</span>):

    <span style="color:#75715e"># Create the parameter grid based on the results of random search </span>
     param_grid <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;bootstrap&#39;</span>: [True],
    <span style="color:#e6db74">&#39;max_depth&#39;</span>: [<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">9</span>],
    <span style="color:#e6db74">&#39;max_features&#39;</span>: [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>],
    <span style="color:#e6db74">&#39;min_samples_leaf&#39;</span>: [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>],
    <span style="color:#e6db74">&#39;min_samples_split&#39;</span>: [<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">10</span>],
    <span style="color:#e6db74">&#39;n_estimators&#39;</span>: [<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">200</span>]
    }

    <span style="color:#75715e"># Create a based model</span>
    <span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestRegressor
    rf <span style="color:#f92672">=</span> RandomForestRegressor()

    
<span style="color:#75715e"># Instantiate the grid search model</span>
<span style="color:#f92672">import</span> dask_searchcv <span style="color:#f92672">as</span> dcv
grid_search <span style="color:#f92672">=</span> dcv<span style="color:#f92672">.</span>GridSearchCV(estimator <span style="color:#f92672">=</span> rf, param_grid <span style="color:#f92672">=</span> param_grid, cv <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>)
grid_search<span style="color:#f92672">.</span>fit(data, target)
grid_search<span style="color:#f92672">.</span>best_params_</code></pre></div>
<h1 id="official-doc-dask-distributed-kubernetes-a-id-official-a">Official Doc Dask.distributed &amp; Kubernetes <a id="official"></a></h1>

<h2 id="quickstart-official-doc">QuickStart Official Doc</h2>

<h4 id="restart-cluter-scheduler-at-error">Restart Cluter/Scheduler at error</h4>

<p><code>c.restart()</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client, progress

client <span style="color:#f92672">=</span> Client(<span style="color:#e6db74">&#39;172.17.0.2:8786&#39;</span>)
client</code></pre></div>
<table style="border: 2px solid white;">
<tr>
<td style="vertical-align: top; border: 0px solid white">
<h3>Client</h3>
<ul>
  <li><b>Scheduler: </b>tcp://172.17.0.2:8786
  <li><b>Dashboard: </b><a href='http://172.17.0.2:8787/status' target='_blank'>http://172.17.0.2:8787/status</a>
</ul>
</td>
<td style="vertical-align: top; border: 0px solid white">
<h3>Cluster</h3>
<ul>
  <li><b>Workers: </b>3</li>
  <li><b>Cores: </b>6</li>
  <li><b>Memory: </b>6.29 GB</li>
</ul>
</td>
</tr>
</table>

<h3 id="map-and-submit">Map and Submit</h3>

<blockquote>
<p>Coupled to launch compu on cluster - sending (FUNC, *ARG) to remote WORKERS for processing -&gt; returning FUTURE object referring to remote DATA on CLUSTER -&gt; FUTURE returns immediately while comp run remotely in background</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">square</span>(x):
    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">neg</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span>x

A <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(square, range(<span style="color:#ae81ff">10</span>))
B <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(neg, A)
total <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(sum, B)
total<span style="color:#f92672">.</span>result()</code></pre></div>
<pre><code>-285
</code></pre>

<h3 id="gather">Gather</h3>

<blockquote>
<p>map/submit return Future, lightweight tokens referring to results on cluster. By default they STAY ON CLUSTER</p>

<p>Gather results to LOCAL machine either with <code>Future.result</code> method for a single future, or with the <code>Client.gather</code> for many futures at once</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">total

total<span style="color:#f92672">.</span>result() <span style="color:#75715e"># result for single future</span>

client<span style="color:#f92672">.</span>gather(A) <span style="color:#75715e"># gather for many futures</span></code></pre></div>
<p><b>Future: sum</b> <font color="gray">status: </font><font color="black">finished</font>, <font color="gray">type: </font>int, <font color="gray">key: </font>sum-7f3e220448a7f71ff037b16dd2be51d1</p>

<pre><code>-285
</code></pre>

<pre><code>[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
</code></pre>

<h3 id="setup-network">Setup Network</h3>

<ul>
<li>Using CLI (<code>dask-scheduler</code>)</li>
</ul>

<blockquote>
<p>Various ways to deploy these CLI on cluster</p>

<ul>
<li>manual SSH into nodes</li>
<li>auto system like SGE/Torque/Yarn/Mesos</li>
</ul>
</blockquote>

<ul>
<li><h4 id="note-both-scheduler-worker-neet-to-accept-tcp-connections-default-port-8786-and-random-for-workers-if-firewall-need-port-worker-port-keywords">NOTE both scheduler/worker neet to accept TCP connections, default port 8786 and random for workers - if firewall need <code>--port -worker-port</code> keywords</h4></li>

<li><p>Using SSH (<code>dask-ssh</code> opens several SSH to target nodes INIT taking hostnames / IP</p>

<ul>
<li><code>dask-ssh 192.1680.0.1 192.168.0.2 ...</code></li>
<li><code>dask-ssh 192.168.0.{1,2,3,4}</code></li>
<li><code>dask-ssh --hostfile hostfile.txt</code> # list of IPs</li>
<li>dependency: <code>pip install paramiko</code></li>
</ul></li>

<li><p>Using Shared Network File System NFS and Job Scheduler (some clusters profit from NFS to communicate shceduler location to workers)</p>

<ul>
<li><code>dask-scheduler --scheduler-file /path/to/scheduler.json \ dask-worker --scheduler-file /path/to/scheduler.json ...</code></li>
<li>client = Client(scheduler_file=&lsquo;/path/to/scheduler.json&rsquo;)</li>
<li>refer doc for detail SGE&rsquo;s qsub example</li>
</ul></li>

<li><p>Using Python API session manually (listening port and Tornado IOLoop)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> distributed <span style="color:#f92672">import</span> Scheduler
<span style="color:#f92672">from</span> tornado.ioloop <span style="color:#f92672">import</span> IOLoop
<span style="color:#f92672">from</span> threading <span style="color:#f92672">import</span> Thread
loop <span style="color:#f92672">=</span> IOLoop<span style="color:#f92672">.</span>current()
t <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span>loop<span style="color:#f92672">.</span>start, daemon<span style="color:#f92672">=</span>True)
t<span style="color:#f92672">.</span>start()
s <span style="color:#f92672">=</span> Scheduler(loop<span style="color:#f92672">=</span>loop)
s<span style="color:#f92672">.</span>start(<span style="color:#e6db74">&#39;tcp://:8786&#39;</span>)
  
<span style="color:#75715e"># on nodes</span>
<span style="color:#f92672">from</span> distributed <span style="color:#f92672">import</span> Worker
<span style="color:#f92672">from</span> tornado.ioloop <span style="color:#f92672">import</span> IOLoop
<span style="color:#f92672">from</span> threading <span style="color:#f92672">import</span> Thread
loop <span style="color:#f92672">=</span> IOLoop<span style="color:#f92672">.</span>current()
t <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span>loop<span style="color:#f92672">.</span>start, daemon<span style="color:#f92672">=</span>True)
t<span style="color:#f92672">.</span>start()
w <span style="color:#f92672">=</span> Worker(<span style="color:#e6db74">&#39;tcp://127.0.0.1:8786&#39;</span>, loop<span style="color:#f92672">=</span>loop)
w<span style="color:#f92672">.</span>start() <span style="color:#75715e"># choose randomly assigned port</span></code></pre></div></li>

<li><p>Using LocalCluster (<code>from distributed import LocalCluster \ client = LocalCluster(processes=False)</code> IOLoop in background thread)</p></li>

<li><p>Using AWS (see Cloud Deployments)</p></li>

<li><p>Using GC <code>dask-kubernetes</code> + Google Kubernetes Engine</p></li>

<li><p>Cluster Resource Managers (Kubernetes)</p>

<ul>
<li><a href="https://github.com/martindurant/dask-kubernetes">https://github.com/martindurant/dask-kubernetes</a></li>
<li><a href="https://github.com/ogrisel/docker-distributed">https://github.com/ogrisel/docker-distributed</a></li>
<li><a href="https://github.com/hammerlab/dask-distributed-on-kubernetes/">https://github.com/hammerlab/dask-distributed-on-kubernetes/</a></li>
</ul></li>
</ul>

<h3 id="custom-init">Custom INIT</h3>

<ul>
<li><code>--preload</code> allows python file refer to Doc</li>
</ul>

<h3 id="client-primary-entry-point-overall">Client (Primary Entry Point overall)</h3>

<ul>
<li>Ways of interaction:

<ol>
<li>Client caters most <code>concurrent.futures</code> interface with <code>.submit .map</code> <code>Futures</code> obj</li>
<li>Registers as default Dask scheduler, thus running all collections (4 of them: array, bag, df, delayed)</li>
<li>Extra methods operating data remotely (API list)</li>
</ol></li>
</ul>

<h4 id="concurrent-futures">Concurrent.futures</h4>

<ul>
<li>Submit single func call with submit and many with map

<ul>
<li><code>client.submit(func, 10); client.map(func, range(1000))</code></li>
<li>Results LIVE on workers, while submitting as FUTURES will go to machine where stored and run once completed! (ASYNC)</li>
<li><code>y = client.submit(func, x) # a future</code></li>
<li><code>total = client.submit(sum, L) # Map on L, a list of Futures</code></li>
<li>Gather back results by <code>Future.result</code> for single and <code>client.gather</code> for many futures at once</li>
<li><code>x.result(); client.gather(L)</code></li>
<li>BUT aim to minimise commOverhead to local process, best to leave on cluster ops remotely with `submit, map, get, compute</li>
</ul></li>
</ul>

<h4 id="dask-parent-lib-auto-parallel-algo-on-dsets">Dask (Parent lib, auto-parallel algo on dsets)</h4>

<ul>
<li>Client obj registers as default Scheduler - ALL <code>.compute()</code> will auto-start using distributed system on Dask objects

<ul>
<li><code>my_dataframe.sum().compute() # now using client system by default</code></li>
<li>Stop it by <code>set_as_default=False</code> when starting Client</li>
</ul></li>
</ul>

<blockquote>
<h4 id="dask-normal-compute-synchronous-blocking-interpreter-till-complete-dask-distributed-allows-asynchronous-trigging-ops-in-background-and-persist-in-memo-while-taking-on-other-works-typically-handled-with-client-persist-for-large-result-set-and-client-compute-smaller-result">Dask normal <code>.compute()</code> SYNCHRONOUS<code>, blocking interpreter till complete -</code>dask.distributed<code>allows ASYNCHRONOUS trigging ops in background and persist in MEMO while taking on other works - typically handled with</code>Client.persist<code>for large result set and</code>Client.compute` smaller result</h4>

<ul>
<li><code>df = client.persist(df) # trigger all compu keep df in MEMO</code></li>
</ul>
</blockquote>

<h4 id="pure-func-by-default">Pure Func by Default</h4>

<ul>
<li>Default assuming functions are <strong>PURE</strong>, if not <code>pure=False</code></li>
<li>Client link a key to all compu, accessed on Future obj

<ul>
<li><code>from operator import add</code></li>
<li><code>x = client.submit(add, 1, 2)</code></li>
<li><code>x.key</code> # hash code</li>
<li>KEY same across ALL compu with same input across all machines - running above on any machine in ENV getting SAME KEY</li>
<li>Scheduler avoids redundant compu - if result already in MEM, submit or map idempotent in common case</li>
<li>Maybe bad for <strong>IMPURE</strong> func like <code>random</code> hence 2 calls to same func produce diff results by <code>pure=False</code></li>
<li><code>client.submit(np.random.random, 1000, pure=False).key != another</code></li>
</ul></li>
</ul>

<h4 id="tornado-coroutines">Tornado Coroutines</h4>

<ul>
<li><p>ASYNC ENV then blocking funcs listed above become ASYN equivalents - MUST start client with <code>asynchronous=True</code> plus <code>yield</code> or <code>await</code> blocking functions</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a6e22e">@gen.coroutine</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
  client <span style="color:#f92672">=</span> await Client(asynchronous<span style="color:#f92672">=</span>True)
  future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, <span style="color:#f92672">*</span>args)
  result <span style="color:#f92672">=</span> await future
  <span style="color:#66d9ef">return</span> result</code></pre></div>
<ul>
<li><p>If reusing same client in ASYNC and SYNC ENV, apply that keyword at EACH method call</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">client <span style="color:#f92672">=</span> Client() <span style="color:#75715e"># normal blocking client</span>
<span style="color:#a6e22e">@gen.coroutine</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(func, L)
results <span style="color:#f92672">=</span> await client<span style="color:#f92672">.</span>gather(futures, asynchronous<span style="color:#f92672">=</span>True)
<span style="color:#66d9ef">return</span> results</code></pre></div></li>
</ul></li>
</ul>

<h3 id="api-see-doc">API see Doc</h3>

<h3 id="q-a">Q&amp;A</h3>

<ul>
<li>How to use external modules? <code>client.upload_file</code> which supports both standalone file and setuptools&rsquo; .egg files for larger modules</li>
<li>Too many open file descriptors? Linux system refer to User Level FD Limits</li>
<li>Dask handle Data Locality? Yes both in MEM and Disk, e.g. <code>dask.dataframe.read_csv('hdfs://path/to/files.*.csv')</code> signalling name node to see locality</li>
</ul>

<h3 id="diagnosis">Diagnosis</h3>

<h4 id="task-on-and-off-times">Task On and Off Times</h4>

<ul>
<li>Serialisation GRAY</li>
<li>Dependency gathering from peers RED</li>
<li>Disk I/O collecting local data ORANGE</li>
<li>Execution times COLOURED per Taks</li>
<li>Custom dashboard <code>Scheduler plugin</code></li>
</ul>

<h4 id="statistical-profiling">Statistical Profiling</h4>

<ul>
<li>Per 10ms each worker process checks what each worker threads doing, grab call stack and adds to counting data structure - recorded and clearered by second to set record</li>
<li><code>/profile</code> plot on worker zooming into task level or <code>Client.profile</code> query data directly delivering raw data structure used to produce plots</li>
<li>10ms and 1s params controlled by <code>profile-interval</code> and <code>profile-cycle-interval</code> entries in CONFIG.YAML</li>
</ul>

<h3 id="efficiency">Efficiency</h3>

<ul>
<li>Parallel computing done well is responsive and rewarding, BUT speed-bumps ahead</li>
</ul>

<h4 id="leave-data-on-cluster">Leave data on cluster</h4>

<ul>
<li><p>Wait as long as possible to gatehr data locally - if querying large piece of data on cluster often FASTER to SUBMIT func onto that data then to bring local</p></li>

<li><p>E.g. query shape of NPArray on cluster choose:</p>

<ol>
<li><p>SLOW: gather array to local process, call <code>.shape</code></p></li>

<li><p>FAST: Send lambda func up to cluster to compute shape</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random, (<span style="color:#ae81ff">1000</span>,<span style="color:#ae81ff">1000</span>)) <span style="color:#75715e"># x is future</span>
<span style="color:#75715e"># SLOW</span>
x<span style="color:#f92672">.</span>result()<span style="color:#f92672">.</span>shape() <span style="color:#75715e"># slow down by data transfer</span>
<span style="color:#75715e"># FAST</span>
client<span style="color:#f92672">.</span>submit(<span style="color:#66d9ef">lambda</span> a: a<span style="color:#f92672">.</span>shape, x)<span style="color:#f92672">.</span>result()</code></pre></div></li>
</ol></li>
</ul>

<h4 id="user-larger-tasks">User larger tasks</h4>

<ul>
<li><h4 id="scheduler-adds-aout-1ms-overhead-per-task-or-future-obj-slow-if-billions-of-tasks-if-func-run-faster-than-100ms-then-might-not-see-any-speedup-from-using-distributed-computing">scheduler adds aout 1ms overhead per task or Future obj, slow if billions of tasks - if func run faster than 100ms then might not see any speedup from using distributed computing !!</h4></li>

<li><p>SOLUTION: BATCH INPUT INTO LARGER CHUNKS</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># SLOW</span>
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(f, seq)
len(futures) <span style="color:#75715e"># 100000000000 avoid large numbers of futures</span>
<span style="color:#75715e"># FAST</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f_many</span>(chunk):
  <span style="color:#66d9ef">return</span> [f(x) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> chunk]
<span style="color:#f92672">from</span> toolz <span style="color:#f92672">import</span> partition_all
chunks <span style="color:#f92672">=</span> partition_all(<span style="color:#ae81ff">10000000</span>, seq) <span style="color:#75715e"># collect into groups of size 1000</span>
futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(f_many, chunks)
len(futures) <span style="color:#75715e"># 1000 compu on larger pieces of data at once</span></code></pre></div></li>
</ul>

<h4 id="adjust-betweeen-threads-and-processes">Adjust betweeen Threads and Processes!!!</h4>

<ul>
<li>Default single Worker runs many compu in parallel maxing out threads on machine cores! Using pure Python func may not be optimal thus prefer to run several worker processes on each node, each using one thread! When config cluster may want to use this:

<ul>
<li><code>dask-worker ip:port --nprocs 8 --nthreads 1</code></li>
</ul></li>
<li>NOTE if primarily using NP, PD, SciPy, SKL, Numba or other C/Fortran/LLVM/Cython accelerated libs then not an issue, code likely optimal for use with MULTI-THREADING</li>
</ul>

<h4 id="dont-go-distributed">DONT GO Distributed</h4>

<ul>
<li>Consider Dask and concurrent.futures modules with simiarl API operating on single machine - accelerating code through other means - better algo, data structures, stroage format, or Cython etc 10x speed boost</li>
</ul>

<h3 id="limit">LIMIT</h3>

<h4 id="performance">Performance</h4>

<ul>
<li><p><strong>Central scheduler spends 00s us (Microsecond) per task - for optimality, TASK DURATION &gt; 10-100ms</strong></p></li>

<li><p>Dask cannot parallelise within individual task - should be comfortable size so as not to overwhlem any particular worker</p></li>

<li><p>Dask assigns tasks to worker heristically - often right but non-optimal decision</p></li>

<li><h4 id="workers-are-just-python-processes-inheriting-all-pros-and-cons-of-python-not-bound-or-limit-in-any-way-production-may-wish-to-run-dask-workers-within-containers">Workers are just Python processes, inheriting all pros and cons of Python - Not bound or limit in any way, PRODUCTION may wish to run dask-workers within CONTAINERS !!</h4></li>
</ul>

<h4 id="assumptions-on-func-and-data">Assumptions on FUNC and DATA</h4>

<ul>
<li>All func must be <strong>serialiseable</strong> either with PICKLE or COULDPICKLE, often the case bar farily exotic cases check by

<ul>
<li><code>from cloudpickle import dumps, loads \ loads(dumps(my_object))</code></li>
</ul></li>
<li>All data must be serialisable either pickle or coud pickel or using dask custom serialisation system</li>
<li>Dask may run func multi-times, such as if worker holding an middle result dies - any side effects should be idempotent!!</li>
</ul>

<h3 id="security">Security</h3>

<ul>
<li>Dask enables remote execution of arbitrary code, hsuld only HOST dask-workers within network trusted</li>
</ul>

<h3 id="data-locality">Data Locality</h3>

<ul>
<li>Data movement needlessly limits performance

<ul>
<li><code>futures = client.scatter(range(10)</code> each worker with 2 cores and scatter out</li>
</ul></li>
</ul>

<h4 id="user-control">User Control</h4>

<ul>
<li>complex algo finer control - current hardwar GPUs or database connetions may restrict est of valid workers for particular task</li>
<li>Thus <code>workers=</code> options:

<ul>
<li>`future = client.submit(func, *args, workers=[&lsquo;Alice&rsquo;])</li>
<li>required data always assigned to Alice, this restriction is only preference not strict, <code>allow_other_workers=True</code> signal extreme case</li>
<li>extra scatter func supports broadcast enforcing all data sent to all workers rather than round-robined - if new workers arrive will not auto-receive this data: <code>futures =client.scatter([1,2,3], broadcast=True)</code></li>
<li>naming can be use or IP <code>dask-worker scheduler_address:8786 --name Alice</code></li>
</ul></li>
</ul>

<h4 id="worker-with-compute-persist">Worker with Compute/Persist</h4>

<ul>
<li><p><code>worker=</code> keyword in <code>scatter, submit, map</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">client<span style="color:#f92672">.</span>submit(f, x, workers<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;127.0.0.1&#39;</span>)
client<span style="color:#f92672">.</span>submit(f, x, workers<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;127.0.0.1:55852&#39;</span>)
client<span style="color:#f92672">.</span>submit(f, x, workers<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;192.168.1.101&#39;</span>, <span style="color:#e6db74">&#39;192.168.1.100&#39;</span>])
<span style="color:#75715e"># more complex compu, specify certain parts of compu run on certain workers</span>
x <span style="color:#f92672">=</span> delayed(f)(<span style="color:#ae81ff">1</span>)
y <span style="color:#f92672">=</span> delayed(f)(<span style="color:#ae81ff">2</span>)
z <span style="color:#f92672">=</span> delayed(g)(x, y)
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(z, workers<span style="color:#f92672">=</span>{z: <span style="color:#e6db74">&#39;127.0.0.1&#39;</span>,
                                x: <span style="color:#e6db74">&#39;192.168.0.1&#39;</span>})

future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(z, workers<span style="color:#f92672">=</span>{(x, y): [<span style="color:#e6db74">&#39;192.168.1.100&#39;</span>, <span style="color:#e6db74">&#39;192.168.1.101:9999&#39;</span>]})
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(z, workers<span style="color:#f92672">=</span>{(x, y): <span style="color:#e6db74">&#39;127.0.0.1&#39;</span>},
                    allow_other_workers<span style="color:#f92672">=</span>True)
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(z, workers<span style="color:#f92672">=</span>{(x, y): <span style="color:#e6db74">&#39;127.0.0.1&#39;</span>},
                    allow_other_workers<span style="color:#f92672">=</span>[x])
df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;s3://...&#39;</span>)
df <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>persist(df, workers<span style="color:#f92672">=</span>{df: <span style="color:#f92672">...</span>})</code></pre></div></li>
</ul>

<h3 id="managing-computation">Managing Computation</h3>

<ul>
<li>**Data and Computation in Dask.distributed always in 1 of 3 states

<ol>
<li>Concrete values in local MEM, e.g. integer 1 or NPArray in local process</li>
<li>Lazy computations in dask graph, perhaps stored in dask.delayed or dask.dataframe</li>
<li>Running compu or remote data, via Future pointing to compu currently in flight</li>
</ol></li>
</ul>

<h4 id="dask-collections-to-concrete-values">Dask Collections to Concrete Values</h4>

<ul>
<li>Turn any dask collection into concrete value by <code>.compute()</code> or <code>dask.compute</code>

<ul>
<li>Blocking until compu done, going straight from lazy dask collection to a concrete value in local MEM</li>
<li>Most typical, great when data already in MEM and want small, fast results at local process</li>
<li><code>df = dd.read_csv('s3://...') \ df.value.sum().compute()</code></li>
<li>HOWEVER, this way breaks down if trying to bring entire Dset back to local RAM <code>MemoryError()</code></li>
<li>Forcing wait till compu done before handing back control of interpreter</li>
</ul></li>
</ul>

<h4 id="dask-collection-to-futures">Dask Collection to Futures</h4>

<ul>
<li>Async submit lazy dask graphs to run on cluster with <code>client.compute</code> and <code>client.persist</code></li>
<li>Return Future at once - further queried to determine state of compu

<ul>
<li><code>.compute</code> takes collection return single future</li>
<li><code>total = client.compute(df.sum()) \ total # future \ total.result() # block until done</code></li>
<li>As single future result MUST fit single worker machine, only works when results small fit RAM</li>
<li>FAIL: <code>future = client.compute(df)</code> - blows up RAM</li>
<li>GOOD: use <code>client.persist</code></li>
<li><code>.persist</code> submits task graph behind collection, getting Futures for call of top-most task (e.g. one Future for each Pandas DF in Dask.df)</li>
<li>Then returns copy of collection pointing to these futures instead of previous graph</li>
<li>New collection semantically same but now points to actively running data not lazy graph</li>
<li><code>df.dask</code> - recipe to compute df in chunks</li>
<li><code>df = client.persist(df)</code> - start compu</li>
<li><code>df.dask</code> - now points to running futures</li>
<li>collection returned at once while compu in run detached on cluster - ending all futures done then more queries on it very fast</li>
<li><strong>Typically the workflow defined a compu with <code>dask.dataframe, dask.delayed</code> until a point where nice Dset to work from, then persist that collection to cluster then perform many fast queries off the resulting collection</strong></li>
</ul></li>
</ul>

<h4 id="concrete-value-to-futures">Concrete Value to Futures</h4>

<ul>
<li><p>Get futures from few ways: 1) above, by wrapping Futures with Dask collections , 2) submitting data / task directly to cluster by <code>client.scatter, client.submit or client.map</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>scatter(args) <span style="color:#75715e"># Send data</span>
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(function, <span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwrags) <span style="color:#75715e"># Send single task</span>
futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(function, sequence, <span style="color:#f92672">**</span>kwargs) <span style="color:#75715e"># Send many tasks</span></code></pre></div></li>

<li><p>now <code>*args or **kwargs</code> can be nromal Python obj or other <code>Future</code> if to link tasks with dependencies</p></li>

<li><p><strong>unlike Dask collections (dask.delayed) these task submissions happen at once, the concurrent.futures interface very similar to dask.delayed except that execution is immediate not lazy</strong></p></li>
</ul>

<h4 id="futures-to-concrete-values">Futures to Concrete Values</h4>

<ul>
<li>Turn each Future into concrete value in local process via <code>future.result()</code> - can convert collection of futures into values <code>client.gather</code></li>
</ul>

<h4 id="futures-to-dask-collections">Futures to Dask Collections</h4>

<ul>
<li>As Collection to futures, common to have currently computing Future within Dask graphs</li>
<li>This enables further compu on top of currently running - most often done with <code>dask.delayed</code> workflows on custom compu:

<ul>
<li><code>x = delayed(sum)(futures)</code></li>
<li><code>y = delayed(product)(futures)</code></li>
<li><code>future = client.compute(x + y)</code></li>
</ul></li>
<li>Mixing two forms allow building and submitting compu in stages like <code>sum(...) + product(...)</code></li>
<li>This often valuable if want to wait to see values of certain parts of compu before further proceeding</li>
<li>Submitting many ocmpu at ocne allows scheduler to be slightly more intelligent when determinig what gets trun</li>
</ul>

<h3 id="managing-mem">Managing MEM</h3>

<ul>
<li>Storing results of tasks in distr.MEM of worker nodes - tracking all data free as need</li>
<li>Done result cleared from MEM soonest - result kept in MEM if either:

<ol>
<li>A client holds a future pointing to this task - data should persist in RAM to gather data on demand</li>
<li>Task is necessary for ongoing compu working to produce final results pointed to by futures - these tasks removed once no ongoing tasks required</li>
</ol></li>

<li><p>When users hold future or persisted collections (which contain many such futures inside <code>.dask</code> attr) they pin those results to active MEM</p></li>

<li><p><strong>when user deletes futures or collections from local process scheduler removes linked data from Dsitributed RAM, FOR this relationship, distributed MEM reflects state of local MEM, a user may free distributed MEM on cluster by deleting persisted collections in local session</strong></p></li>
</ul>

<h4 id="creating-futures">Creating Futures</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Client<span style="color:#f92672">.</span>submit(func, <span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs) <span style="color:#75715e"># submit func to scheduler</span>
Client<span style="color:#f92672">.</span>map(func, <span style="color:#f92672">*</span>iterables, <span style="color:#f92672">**</span>kwargs) <span style="color:#75715e"># map a func on seq of args</span>
Client<span style="color:#f92672">.</span>compute(collections[, sync, <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> ]) <span style="color:#75715e"># compu dask collection on cluster</span>
Client<span style="color:#f92672">.</span>persist(collections[, <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> ]) <span style="color:#75715e"># persist dask collections on cluster</span>
Client<span style="color:#f92672">.</span>scatter(data[, workers, broadcast, <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> <span style="color:#f92672">.</span> ]) <span style="color:#75715e"># scatter data into distr.mem</span></code></pre></div>
<p><strong>The submit and map methods handle raw Python functions. The compute and persist methods handle Dask collections like arrays, bags, delayed values, and dataframes. The scatter method sends data directly from the local process.</strong></p>

<h4 id="persisting-collections">Persisting Collections</h4>

<ul>
<li>calls to <code>client.compute or client.persist</code> submit task graphs to cluster and retur future pointing to particular ouptut tasks</li>

<li><p>compute returns single future per input, persist reutns a copy of collection with each block or partition repalced by single future, inshort <strong>use <code>persist</code> to keep full collection on cluster and <code>compute</code> when want a small result as a single future - persist is more common and often used with collections:</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#75715e"># Construct dataframe, no work happens &gt;&gt;&gt; df = dd.read_csv(...)</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> df <span style="color:#f92672">=</span> df[df<span style="color:#f92672">.</span>x <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>]
<span style="color:#f92672">&gt;&gt;&gt;</span> df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>assign(z <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>x <span style="color:#f92672">+</span> df<span style="color:#f92672">.</span>y)
<span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#75715e"># Pin data in distributed ram, this triggers computation &gt;&gt;&gt; df = client.persist(df)</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#75715e"># continue operating on df</span></code></pre></div></li>
</ul>

<blockquote>
<p>Build compu parsing CSV, filtering, adding col, up till this point all LAZY - simply a recipe to graph in df object -&gt; <code>.persist(df)</code> cut this graph off df sending it up to scheduler receiving future in return creating new df with shallow graph pointing right to them - more or less at once - continue working on new df while cluster running graph in back</p>
</blockquote>

<h4 id="difference-with-dask-compute">Difference with dask.compute</h4>

<ul>
<li><code>client.persist(df), client.compute(df)</code> ASYNC so differ from <code>df.compute()</code> or <code>dask.copute</code>, which blocks until result available</li>
<li><code>.compute()</code> NOT persist any data on cluster - also brings entire result back to local -&gt; unwise to use on large data</li>
<li>BUT <code>compute()</code> very easy for smaller result as concrete result most other tools expect !</li>

<li><p>Typically use ASYNC ones to set up large collections and <code>df.compute()</code> for fast analyses:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#75715e"># df.compute() # This is bad and would likely flood local memory</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> df <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>persist(df) <span style="color:#75715e"># This is good and asynchronously pins df</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> df<span style="color:#f92672">.</span>x<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>compute() <span style="color:#75715e"># This is good because the result is small</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(df<span style="color:#f92672">.</span>x<span style="color:#f92672">.</span>sum()) <span style="color:#75715e"># This is also good but less intuitive</span></code></pre></div></li>
</ul>

<h4 id="clearing-data">Clearing data</h4>

<ul>
<li>Remove data from cluster RAM by removing collection from local process - remote data removed once all Futures poiting to it removed from all client machiens <code>del df # deleting local data often deletes remote data</code>

<ul>
<li>if this the only copy then will trigger cluster to delete as well</li>
<li>BUT if multiple copies or other colections based on it then have to delete them all!</li>
<li><code>df2 = df[df.x &lt; 10] \ del df # would not delete, as df2 still tracks the futures</code></li>
</ul></li>
</ul>

<h4 id="hard-clearing-ddata">Hard Clearing ddata</h4>

<ul>
<li><code>client.cancel(df) # kills df, df2 and all other dependent compu</code></li>
<li>OR, retart cluster</li>
</ul>

<h4 id="resilience">Resilience</h4>

<ul>
<li>results not intentionally COPIED unless necessary for compu on other nodes - resilience via recompu by keeping provenance of any result - if a worker node down scheduler able to recompu ALL its results</li>
<li>FULL graph for any desired future kept until no references to future</li>
</ul>

<h3 id="advanced-techniques">Advanced techniques</h3>

<ul>
<li></li>
</ul>

<h1 id="matthew-rocklin-talks-a-id-rocklin-a">Matthew Rocklin Talks <a id="rocklin"></a></h1>

<h2 id="dask">DASK</h2>

<ul>
<li>Dynamic task shceduler for generic applications</li>
<li>Handles data locality, resilience, work stealing, etc</li>
<li>With 10ms roundtrip latencies and 200us overheads</li>
<li>Native Pythn lib respecting protocols</li>
<li>Lightweight and well supported</li>
</ul>

<h3 id="single-machine-scheduler">Single Machine Scheduler</h3>

<ul>
<li>Parallel CPU: uses multiple threads or processes</li>
<li>Minimise RAM: choose tasks to remove intermediates</li>
<li>Low overhead: ~100us per task</li>
<li>Concise: ~1000 LOC</li>
<li>Real world workloads: Under heavy load by diff projects</li>
</ul>

<h3 id="distributed-scheduler">Distributed Scheduler</h3>

<ul>
<li>Distributed: One scheduler coordinates many workers</li>
<li>Data local: moves compu to correct worker</li>
<li>Asynchronous: continous non-blocking conversation</li>
<li>Multi-user: several users share same system</li>
<li>HDFS Aware: works well with HDFS, S3, YARN etc</li>
<li>Solidly supports: dask.array, dask.dataframe, dask.bag, dask.delayed, concurrent.futures</li>
<li>Less Concise: ~5000 LOC Tornado TCP application</li>
</ul>

<blockquote>
<p>all of logic is hackable Python, separate from Tornado</p>
</blockquote>

<h3 id="concurrent-futures-pep-3148">Concurrent.futures (PEP 3148)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> as_completed

data <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">100</span>)

futures <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data:
    <span style="color:#66d9ef">if</span> x <span style="color:#f92672">%</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(inc, x)
    <span style="color:#66d9ef">else</span>:
        future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(dec, x)
    futures<span style="color:#f92672">.</span>append(future)

done <span style="color:#f92672">=</span> as_completed(futures)

<span style="color:#66d9ef">while</span> True:
    <span style="color:#66d9ef">try</span>:
        a <span style="color:#f92672">=</span> next(done)
        b <span style="color:#f92672">=</span> next(done)
    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">StopIteration</span>:
        <span style="color:#66d9ef">break</span>
        
    future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(add, a, b)
    done<span style="color:#f92672">.</span>add(future)</code></pre></div>
<h3 id="async-await">Async/Await</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">async <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
    total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    async <span style="color:#66d9ef">with</span> Client(<span style="color:#e6db74">&#39;dask-scheduler:8786&#39;</span>, start<span style="color:#f92672">=</span>False) <span style="color:#66d9ef">as</span> client:
        futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(inc, range(<span style="color:#ae81ff">100</span>))
        async <span style="color:#66d9ef">for</span> future <span style="color:#f92672">in</span> as_completed(futures):
            result <span style="color:#f92672">=</span> await future
            total <span style="color:#f92672">+=</span> result
    <span style="color:#66d9ef">print</span>(total)

<span style="color:#f92672">from</span> tornado.ioloop <span style="color:#f92672">import</span> IOLoop
IOLoop<span style="color:#f92672">.</span>current()<span style="color:#f92672">.</span>add_callback(f)</code></pre></div>
<blockquote>
<p>By reusing existing API and protocols, Dask enables parallelsiation of existing codebases with minimal refactoring</p>
</blockquote>

<p>​</p>

<h3 id="dask-distributed-scheduler-even-on-single-machine"><code>dask.distributed</code> Scheduler (Even on Single Machine)</h3>

<blockquote>
<p>Keynotes</p>

<ol>
<li>Motivation to use dask.distributed shceduler</li>
<li>Jim Crist&rsquo;s talk on bokeh visualisation</li>
<li>concurrent futures API

<ul>
<li>flexible like dask.delayed</li>
<li>real-time control</li>
<li>works great with collections</li>
<li>fully async/await compliant</li>
</ul></li>
</ol>

<p>Hard and Fun DevOps</p>

<ol>
<li>Collections (array, bag, dataframe)

<ul>
<li>Dense linalg / Sparse arrays / Streaming Pandas</li>
<li>GeoPandas, ML (Tom Augspurger, Jim Crist)</li>
</ul></li>
<li>Asynchronous Algo

<ul>
<li>Parameter server style algo (GLM)</li>
</ul></li>
</ol>
</blockquote>

<ul>
<li>Advanced scheduler on local mahcine

<ol>
<li>get diagnostics visualisation via Bokeh</li>
<li>get new features (e.g. .persist())</li>
<li>scale out if necessary</li>
<li>almost always more efficient than multiprocessing scheduler</li>
</ol></li>

<li><p>Ligthweight</p>

<ol>
<li><p>Worker stepup, task submission, result retrieval, shutdown:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%%</span>time
<span style="color:#66d9ef">with</span> Client(processes<span style="color:#f92672">=</span>False) <span style="color:#66d9ef">as</span> client:
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(<span style="color:#66d9ef">lambda</span> x: x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>)
<span style="color:#66d9ef">print</span>(future<span style="color:#f92672">.</span>result())</code></pre></div></li>
</ol></li>
</ul>

<h3 id="customised-programme-with-dask-example">Customised Programme with Dask (Example)</h3>

<h4 id="futures-api">Futures API</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># start a local clsuter</span>
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client
client <span style="color:#f92672">=</span> Client()

<span style="color:#75715e"># Submit single task to run in background </span>
<span style="color:#75715e"># Worker runs add(1,2), stores restul in local RAM</span>
<span style="color:#f92672">from</span> operator <span style="color:#f92672">import</span> add
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(add, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>) 

<span style="color:#75715e"># Learn about status asynchronously</span>
future <span style="color:#75715e"># status: finished</span>

<span style="color:#75715e"># block and gather result</span>
future<span style="color:#f92672">.</span>result()</code></pre></div>
<h4 id="track-dependencies-on-the-fly">Track dependencies ON-THE-FLY</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>sumbit(f, <span style="color:#ae81ff">1</span>)
y <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(f, <span style="color:#ae81ff">2</span>)
z <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(g, x, y) <span style="color:#75715e"># submit task on futures</span>

<span style="color:#75715e"># updates happen in background</span>
futures <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(f, x) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> L]

<span style="color:#75715e"># manipulate computations on the fly</span>
<span style="color:#75715e"># submit new tasks during execution</span>
<span style="color:#75715e"># even while previous tasks still flying</span>
finished <span style="color:#f92672">=</span> [future <span style="color:#66d9ef">for</span> future <span style="color:#f92672">in</span> futures <span style="color:#66d9ef">if</span> future<span style="color:#f92672">.</span>status <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;finished&#39;</span>]
results <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>gather(finished)
new_futures <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(g,x) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> <span style="color:#f92672">...</span>]</code></pre></div>
<h4 id="convenient-methods-exist-to-support-asynchronous-workloads">Convenient methods exist to support asynchronous workloads</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># iterate over futures as they complete </span>
<span style="color:#75715e"># part of standard concurrent.futures API</span>
<span style="color:#75715e"># Quit early if having a good enough result </span>
<span style="color:#75715e"># cancel remaining work</span>
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> as_completed

future <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>sumbit(func, <span style="color:#f92672">*</span>args) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> L]

iterator <span style="color:#f92672">=</span> as_completed(futures)

best <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> future <span style="color:#f92672">in</span> iterators:
    result <span style="color:#f92672">=</span> future<span style="color:#f92672">.</span>result()
    best <span style="color:#f92672">=</span> max(best, result)
    <span style="color:#66d9ef">if</span> best <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">100</span>: 
        <span style="color:#66d9ef">break</span>
        
client<span style="color:#f92672">.</span>cancel(iterator<span style="color:#f92672">.</span>futures)

<span style="color:#75715e"># Or continue submit more tasks </span>
<span style="color:#75715e"># add to iterator </span>
<span style="color:#75715e"># simple way to create asynchronous iterative algo</span>
total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> future <span style="color:#f92672">in</span> iterators:
    result <span style="color:#f92672">=</span> future<span style="color:#f92672">.</span>result()
    total <span style="color:#f92672">+=</span> result
    <span style="color:#66d9ef">if</span> result <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">10</span>:
        a <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, <span style="color:#f92672">...</span>) <span style="color:#75715e"># submit more work</span>
        b <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, <span style="color:#f92672">...</span>)
        iterator<span style="color:#f92672">.</span>add(a) <span style="color:#75715e"># add to iterator</span>
        iterator<span style="color:#f92672">.</span>add(b)
        
<span style="color:#75715e"># EX: computational</span>
client <span style="color:#f92672">=</span> Client(<span style="color:#e6db74">&#39;localhost:8766&#39;</span>, timeout<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
client

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rosenbrock</span>(point):
    <span style="color:#e6db74">&#34;&#34;&#34;compute rosenbrock func and return point minimal&#34;&#34;&#34;</span>
    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">0.1</span>)
    score <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> point[<span style="color:#ae81ff">0</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> (point[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> point[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
    <span style="color:#66d9ef">return</span> point, score

scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#75715e"># initial random perturbation</span>
best_point <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>) <span style="color:#75715e"># best point so far</span>
best_score <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;inf&#39;</span>)

initial <span style="color:#f92672">=</span> [(random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>), random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>))
           <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>)]

futures <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(rosenbrock, point) <span style="color:#66d9ef">for</span> point <span style="color:#f92672">in</span> initial]

running <span style="color:#f92672">=</span> as_completed(futures)

<span style="color:#66d9ef">for</span> res <span style="color:#f92672">in</span> running:
    point, score <span style="color:#f92672">=</span> res<span style="color:#f92672">.</span>result()
    <span style="color:#66d9ef">if</span> score <span style="color:#f92672">&lt;</span> best_score:
        best_score, best_point <span style="color:#f92672">=</span> score, point
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Current best (</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">, </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">).&#34;</span>
              <span style="color:#e6db74">&#34;Scale: </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (best_point <span style="color:#f92672">+</span> (scale,)))
        
    x, y <span style="color:#f92672">=</span> best_point
    new_point <span style="color:#f92672">=</span> (x <span style="color:#f92672">+</span> random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span>scale, scale),
                 y <span style="color:#f92672">+</span> random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span>scale, scale))
    new_point <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(rosenbrock, new_point)
    
    running<span style="color:#f92672">.</span>add(new_point)
    
    scale <span style="color:#f92672">*=</span> <span style="color:#ae81ff">0.99</span>
    
    <span style="color:#66d9ef">if</span> scale <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.001</span>:
        <span style="color:#66d9ef">break</span></code></pre></div>
<h4 id="worker-starts-client-scheduler">Worker Starts Client/Scheduler!</h4>

<ul>
<li><p>Submit tasks from tasks</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># tasks can get their own client </span>
<span style="color:#75715e"># Remote client controls cluster</span>
<span style="color:#75715e"># Task-on-worker can do anything you can do locally</span>

<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> get_client, get_worker, secede, fire_and_forget

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">func</span>(<span style="color:#f92672">...</span>):
client <span style="color:#f92672">=</span> get_client()
futures <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(<span style="color:#f92672">...</span>) <span style="color:#66d9ef">for</span> <span style="color:#f92672">...</span>]
results <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>gather(futures)
<span style="color:#66d9ef">return</span> sum(results)

future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, <span style="color:#f92672">...</span>)

<span style="color:#75715e"># EX: fibonnacii</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fib</span>(n):
<span style="color:#66d9ef">if</span> n <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> n <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
    <span style="color:#66d9ef">return</span> n
<span style="color:#66d9ef">else</span>:
    client <span style="color:#f92672">=</span> get_client()
    a <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(fib, n <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
    b <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(fib, n <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span>)
    <span style="color:#66d9ef">return</span> a<span style="color:#f92672">.</span>result() <span style="color:#f92672">+</span> b<span style="color:#f92672">.</span>result()
    
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(fib, <span style="color:#ae81ff">1000</span>)</code></pre></div></li>

<li><p>Multi-client coordination</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># multiple clients, communicating</span>

<span style="color:#75715e"># multi-producer/consumer queue</span>
<span style="color:#75715e"># send along small data for futures</span>
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Queue
q <span style="color:#f92672">=</span> Queue()
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>scatter(my_numpy_array)
q<span style="color:#f92672">.</span>put(<span style="color:#ae81ff">123</span>)
x <span style="color:#f92672">=</span> q<span style="color:#f92672">.</span>get()

<span style="color:#75715e"># Global singleton value</span>
<span style="color:#75715e"># send along small data or futures</span>
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Variable
v <span style="color:#f92672">=</span> Variable()
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>scatter(my_numpy_array)
v<span style="color:#f92672">.</span>set(<span style="color:#ae81ff">123</span>)
x <span style="color:#f92672">=</span> v<span style="color:#f92672">.</span>get()</code></pre></div></li>

<li><p>Multi-consumer Multi-producer system</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Workers start clients</span>
<span style="color:#75715e"># Tasks can submit more tasks</span>
<span style="color:#75715e"># can do anything you can do locally</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">producer</span>():
client <span style="color:#f92672">=</span> get_client()
<span style="color:#66d9ef">while</span> <span style="color:#f92672">not</span> stop<span style="color:#f92672">.</span>get():
    data <span style="color:#f92672">=</span> get_data()
    future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>scatter(data)
    q<span style="color:#f92672">.</span>put(future)
        
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">consumer</span>():
client <span style="color:#f92672">=</span> get_client()
<span style="color:#66d9ef">while</span> <span style="color:#f92672">not</span> stop<span style="color:#f92672">.</span>get():
    future <span style="color:#f92672">=</span> q<span style="color:#f92672">.</span>get()
    data <span style="color:#f92672">=</span> future<span style="color:#f92672">.</span>result()
    <span style="color:#75715e"># do stuff with data</span>
q <span style="color:#f92672">=</span> Queue()
stop <span style="color:#f92672">=</span> Variable()
stop<span style="color:#f92672">.</span>set(False)

producers <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(producer, <span style="color:#f92672">...</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(n)]
consumers <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(consumer, <span style="color:#f92672">...</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(m)]</code></pre></div></li>

<li><p>Fully async await compliant</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># support async/await syntax</span>
<span style="color:#75715e"># support Tornado and AsyncIO event loops</span>
async <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
client <span style="color:#f92672">=</span> await Client(asynchronous<span style="color:#f92672">=</span>True)
    
futures <span style="color:#f92672">=</span> [client<span style="color:#f92672">.</span>submit(f, x) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> L]
async <span style="color:#66d9ef">for</span> future <span style="color:#f92672">in</span> as_completed(futures):
    result <span style="color:#f92672">=</span> await future
    <span style="color:#75715e"># do things with result</span></code></pre></div></li>

<li><p>Specify resource constriants like RAM or GPU</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># specify resources contrs</span>
<span style="color:#75715e"># Good for GPU high RAM tasks</span>
dask<span style="color:#f92672">-</span>worker <span style="color:#f92672">...</span> <span style="color:#f92672">--</span>resources <span style="color:#e6db74">&#34;GPU=2 FOO=1&#34;</span>
dask<span style="color:#f92672">-</span>worker <span style="color:#f92672">...</span> <span style="color:#f92672">--</span>resources <span style="color:#e6db74">&#34;GPU=1 MEMORY=100e9&#34;</span>

future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, x, resources<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;GPU&#39;</span>: <span style="color:#ae81ff">1</span>})
future <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(func, x, resources<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;MEMORY&#39;</span>: <span style="color:#ae81ff">60e9</span>})</code></pre></div></li>
</ul>

<h1 id="jim-crist-talks-a-id-jim-a">Jim Crist Talks <a id="jim"></a></h1>

<h3 id="parallel-numpy-and-pandas-through-task-scheduling">Parallel NumPy and Pandas through Task Scheduling</h3>

<blockquote>
<p>Collections -&gt; Graphs -&gt; Schedulers</p>

<ol>
<li>Collections (array, bag, dataframe, imperative)</li>
<li>Graphs</li>
<li>Schedulers (synchronous, threaded, multiprocessing, distributed)</li>
</ol>

<p>Collections build task graphs -&gt; Schedulers execute task graphs -&gt; Graph specification = uniting interface</p>

<p>Dask Specification</p>

<ol>
<li>Dictionary of {name: task}</li>
<li>Tasks are tuples of (func, args&hellip;) (lispy syntax)</li>
<li>Args can be names, values, or tasks</li>
</ol>

<p>Decoupling between Collections/Graphing/Scheduler makes possible to creating graph directly to problem</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load</span>(filename):
    <span style="color:#66d9ef">pass</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean</span>(data):
    <span style="color:#66d9ef">pass</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">analyze</span>(sequence_of_data):
    <span style="color:#66d9ef">pass</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">store</span>(result):
    <span style="color:#66d9ef">with</span> open(filename, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> f:
        f<span style="color:#f92672">.</span>write(result)
        
dsk <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;load-1&#39;</span>: (load, <span style="color:#e6db74">&#39;myfile.a.data&#39;</span>),
       <span style="color:#e6db74">&#39;load-2&#39;</span>: (load, <span style="color:#e6db74">&#39;myfile.b.data&#39;</span>),
       <span style="color:#e6db74">&#39;load-3&#39;</span>: (load, <span style="color:#e6db74">&#39;myfile.c.data&#39;</span>),
       <span style="color:#e6db74">&#39;clean-1&#39;</span>: (clean, <span style="color:#e6db74">&#39;load-1&#39;</span>),
       <span style="color:#e6db74">&#39;clean-2&#39;</span>: (clean, <span style="color:#e6db74">&#39;load-2&#39;</span>),
       <span style="color:#e6db74">&#39;clean-3&#39;</span>: (clean, <span style="color:#e6db74">&#39;load-3&#39;</span>),
       <span style="color:#e6db74">&#39;analyze&#39;</span>: (analyze, [<span style="color:#e6db74">&#39;clean-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> i <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>]]),
       <span style="color:#e6db74">&#39;store&#39;</span>: (store, <span style="color:#e6db74">&#39;analyze&#39;</span>)}

<span style="color:#75715e"># Alternatively: dask.imperative</span>
<span style="color:#a6e22e">@do</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load</span>(filename):
    <span style="color:#66d9ef">pass</span>
<span style="color:#a6e22e">@do</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean</span>(data):
    <span style="color:#66d9ef">pass</span>
<span style="color:#a6e22e">@do</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">analyze</span>(sequence_of_data):
    <span style="color:#66d9ef">pass</span>
<span style="color:#a6e22e">@do</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">store</span>(result):
    <span style="color:#66d9ef">with</span> open(filename, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> f:
        f<span style="color:#f92672">.</span>write(result)

files <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;myfile.a.data&#39;</span>,<span style="color:#f92672">...</span>]
loaded <span style="color:#f92672">=</span> [load(f) <span style="color:#66d9ef">for</span> f <span style="color:#f92672">in</span> files]
cleaned <span style="color:#f92672">=</span> [clean(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> loaded]
analyzed <span style="color:#f92672">=</span> analyze(cleaned)
stored <span style="color:#f92672">=</span> store(analyze)</code></pre></div>
<ul>
<li><p>Example - dask.bag (any non-NumPy, non-DataFrame, collections)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> dask.bag <span style="color:#f92672">as</span> db

b <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>from_castra(<span style="color:#e6db74">&#39;reddit.castra&#39;</span> columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;subreddit&#39;</span>, <span style="color:#e6db74">&#39;body&#39;</span>],
               npartitions<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
matches_subreddit <span style="color:#f92672">=</span> b<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> x: x[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;MachineLearning&#39;</span>)
words <span style="color:#f92672">=</span> matches_subreddit<span style="color:#f92672">.</span>pluck(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>map(to_words)<span style="color:#f92672">.</span>concat()
top_words <span style="color:#f92672">=</span> words<span style="color:#f92672">.</span>frequencies()<span style="color:#f92672">.</span>topk(<span style="color:#ae81ff">100</span>, key<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>compute()

<span style="color:#f92672">from</span> wordcloud <span style="color:#f92672">import</span> WordCloud

wc <span style="color:#f92672">=</span> WordCloud()
wc <span style="color:#f92672">=</span> generate_from_frequencies(top_words)
wc<span style="color:#f92672">.</span>to_image()</code></pre></div></li>
</ul>

<h3 id="dataframes-on-cluster">DataFrames on Cluster</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> gcsfs <span style="color:#f92672">import</span> GCSFileSystem
gcs <span style="color:#f92672">=</span> GCSFileSystem(token<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cloud&#39;</span>)

gcs<span style="color:#f92672">.</span>ls(<span style="color:#e6db74">&#39;path/to/csv&#39;</span>)

<span style="color:#f92672">import</span> dask.dataframe <span style="color:#f92672">as</span> dd

df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;gcs://path/to/csv&#39;</span> parse_dates<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;datecolumns&#39;</span>], storage_options<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;token&#39;</span>:<span style="color:#e6db74">&#39;cloud&#39;</span>})
df <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>persis(df)
progress(df)</code></pre></div>
<h4 id="parallelise-normal-python-code">Parallelise Normal Python code</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%%</span>time
zs <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">256</span>):
    x <span style="color:#f92672">=</span> inc(i)
    y <span style="color:#f92672">=</span> dec(x)
    z <span style="color:#f92672">=</span> add(x, y)
    zs<span style="color:#f92672">.</span>append(z)
    
zs <span style="color:#f92672">=</span> dask<span style="color:#f92672">.</span>persist(<span style="color:#f92672">*</span>zs)
total <span style="color:#f92672">=</span> dask<span style="color:#f92672">.</span>delayed(sum)(zs)

total<span style="color:#f92672">.</span>compute()

<span style="color:#75715e"># example</span>
futures <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, range(<span style="color:#ae81ff">1000</span>))
total <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(sum, futures)
total<span style="color:#f92672">.</span>result()</code></pre></div>
<h2 id="long-scipy-tutorial-2017-a-id-long-a">Long SciPy Tutorial 2017 <a id="long"></a></h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># METHODS / ATTRIBUTES ACCESS ON DELAYED</span>
<span style="color:#75715e"># ALL TOUCHED DELAYED :D</span>

<span style="color:#f92672">from</span> dask <span style="color:#f92672">import</span> delayed, compute

x <span style="color:#f92672">=</span> delayed(np<span style="color:#f92672">.</span>arange)(<span style="color:#ae81ff">10</span>)
y <span style="color:#f92672">=</span> (x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)[::<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>sum()

y<span style="color:#f92672">.</span>visualize(color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;order&#34;</span>, rankdir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LR&#34;</span>)

<span style="color:#75715e"># .COMPUTE() for single, COMPUTE() for multiple output</span>

min, max <span style="color:#f92672">=</span> compute(y<span style="color:#f92672">.</span>min(), y<span style="color:#f92672">.</span>max())

min,max <span style="color:#75715e"># sharing mid values (y = f(x))</span></code></pre></div>
<p><img src="/Users/Ocean/Desktop/DASK/output_15_0.png" alt="png" /></p>

<pre><code>(25, 25)
</code></pre>

<blockquote>
<p>BEST to dask-LOAD data instead of dask it after</p>
</blockquote>

<p><code>df = delayed(pd.read_csv)(file)</code></p>

<h3 id="dask-dataframe">Dask.dataframe</h3>

<ul>
<li><code>dask.dataframe.read_csv</code> only reads first lines of first file</li>
<li>MAY incur dtype errors if missing</li>

<li><p>SOLUTION</p>

<ol>
<li>specify dtype</li>

<li><p><code>assume_missing</code> to make dask assume col to be int (which disallow missing) are in fact floats (which allows)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dd<span style="color:#f92672">.</span>read_csv(filename, <span style="color:#f92672">...</span> dtype<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;col1&#39;</span>: str, <span style="color:#e6db74">&#39;col2&#39;</span>: float, <span style="color:#e6db74">&#39;col3&#39;</span>: bool})</code></pre></div></li>
</ol></li>
</ul>

<p><strong>Just use normal Pandas syntax!</strong>
<code>df.Column.max().compute()</code></p>

<p><strong>See divisions</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df2 <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;Year&#39;</span>)
df2<span style="color:#f92672">.</span>divisions <span style="color:#75715e"># (1990,...)</span>
df2<span style="color:#f92672">.</span>npartitions</code></pre></div>
<p><strong>Custom Code and DD</strong></p>

<blockquote>
<p>EX, previously <code>to_timestamp</code> not emulated, or need for custom operations</p>
</blockquote>

<ul>
<li><p>wrapper: <code>map_partitions, map_overlap, reduction</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># individual wrapping</span>
hours <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>Time <span style="color:#f92672">//</span> <span style="color:#ae81ff">100</span>
hours_timedelta <span style="color:#f92672">=</span> hours<span style="color:#f92672">.</span>map_partitions(pd<span style="color:#f92672">.</span>to_timedelta, unit<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;h&#39;</span>)
mins <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>Time <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span>
mins_timedelta <span style="color:#f92672">=</span> mins<span style="color:#f92672">.</span>map_partitions(pd<span style="color:#f92672">.</span>to_timedelta, unit<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;m&#39;</span>)

timestamp <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>Date <span style="color:#f92672">+</span> hours_timedelta <span style="color:#f92672">+</span> mins_timedelta

<span style="color:#75715e"># functional wrapping</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_timestamp</span>(df):
hours <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>Time <span style="color:#f92672">//</span> <span style="color:#ae81ff">100</span>
hours_timedelta <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>to_timedelta(hours, unit<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;h&#39;</span>)
mins <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>Time <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span>
mins_timedelta <span style="color:#f92672">=</span> d<span style="color:#f92672">.</span>to_timedelta(minutes, unit<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;m&#39;</span>)
<span style="color:#66d9ef">return</span> df<span style="color:#f92672">.</span>Date <span style="color:#f92672">+</span> hours_timedelta <span style="color:#f92672">+</span> mins_timedelta
timestamp <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>map_partitions(compute_timestamp)</code></pre></div></li>
</ul>

<p><strong>Dask.array / Dask.stack</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> h5py
<span style="color:#f92672">from</span> glob <span style="color:#f92672">import</span> glob
<span style="color:#f92672">import</span> os

<span style="color:#75715e"># generate dataset by prep </span>
filenames <span style="color:#f92672">=</span> sorted(glob(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;data&#39;</span>, <span style="color:#e6db74">&#39;weather-big&#39;</span>, <span style="color:#e6db74">&#39;*.hdf5&#39;</span>)))
dsets <span style="color:#f92672">=</span> [h5py<span style="color:#f92672">.</span>File(filename, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)[<span style="color:#e6db74">&#39;/t2m&#39;</span>] <span style="color:#66d9ef">for</span> fileanme <span style="color:#f92672">in</span> filenames]

arrays <span style="color:#f92672">=</span> [da<span style="color:#f92672">.</span>from_array(dset, chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">500</span>,<span style="color:#ae81ff">500</span>)) <span style="color:#66d9ef">for</span> dset <span style="color:#f92672">in</span> dsets]

x <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>stack(arrays, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

result <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>mean(axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>,<span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>imshow(result, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;RdBu_r&#39;</span>)</code></pre></div>
<p><strong>BAG</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># generating JSON from prep</span>

<span style="color:#f92672">import</span> dask.bag <span style="color:#f92672">as</span> db

b <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>from_sequence([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])

b <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>read_text(os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;data&#39;</span>, <span style="color:#e6db74">&#39;account.*.json.gz&#39;</span>))
b<span style="color:#f92672">.</span>npartitions

c <span style="color:#f92672">=</span> (b<span style="color:#f92672">.</span>filter(iseven)<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)) 
c<span style="color:#f92672">.</span>compute()

<span style="color:#75715e"># read json.gz as lines</span>
lines<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">1</span>) <span style="color:#75715e"># head()-like</span>

js <span style="color:#f92672">=</span> lines<span style="color:#f92672">.</span>map(json<span style="color:#f92672">.</span>loads) <span style="color:#75715e"># disk-loaded as json</span>
js<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">1</span>)

<span style="color:#75715e"># Queries</span>
js<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> record: record[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Alice&#39;</span>)<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">5</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">count_trans</span>(d):
    <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#39;name&#39;</span>: d[<span style="color:#e6db74">&#39;name&#39;</span>],
            <span style="color:#e6db74">&#39;count&#39;</span>: len(d[<span style="color:#e6db74">&#39;transacitons&#39;</span>])}
(js<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> record: record[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Alice&#39;</span>)<span style="color:#f92672">.</span>map(count_trans)<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">5</span>))

<span style="color:#75715e"># pluck: select a field, as from dict, element[filed]</span>
(js<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> record: record[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Alice&#39;</span>)<span style="color:#f92672">.</span>map(count_trans)<span style="color:#f92672">.</span>pluck(<span style="color:#e6db74">&#39;count&#39;</span>)<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">5</span>))

<span style="color:#75715e"># flatten to de-nest</span>
(js<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> record: record[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;Alice&#39;</span>)<span style="color:#f92672">.</span>map(count_trans)<span style="color:#f92672">.</span>flatten()<span style="color:#f92672">.</span>pluck(<span style="color:#e6db74">&#39;amount&#39;</span>)<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>compute())

<span style="color:#75715e"># use foldby instead of groupby (do on DF)</span>
<span style="color:#75715e"># need {key func to group, binary ops passed to reduce per group, combine binary ops on results of two reduce calls on diff parts}</span>
<span style="color:#75715e"># Reduction must be associative</span>
(b<span style="color:#f92672">.</span>foldby(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">%</span> <span style="color:#ae81ff">2</span>,
          binop<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> acc, x: acc <span style="color:#66d9ef">if</span> acc <span style="color:#f92672">&gt;</span> x <span style="color:#66d9ef">else</span> x,
          combine<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> acc1, acc2: acc1 <span style="color:#66d9ef">if</span> acc1 <span style="color:#f92672">&gt;</span> acc2 <span style="color:#66d9ef">else</span> acc2)<span style="color:#f92672">.</span>compute())

<span style="color:#75715e"># Example finding # people sharing name</span>
(js<span style="color:#f92672">.</span>foldby(key<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;name&#39;</span>,
           binop<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> total, x : total <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>,
           initial<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
           combine<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> a, b : a <span style="color:#f92672">+</span> b,
           combine_initial<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
 <span style="color:#f92672">.</span>compute())</code></pre></div>
<p><strong>Diagnostics</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Aid in profiling parallel execution seeing bottleneck</span>
<span style="color:#f92672">from</span> dask.diagnostics <span style="color:#f92672">import</span> Profiler, ResourceProfiler, visualize
<span style="color:#f92672">from</span> bokeh.io <span style="color:#f92672">import</span> output_notebook
output_notebook()

<span style="color:#66d9ef">with</span> Profiler() <span style="color:#66d9ef">as</span> p, ResourceProfiler(<span style="color:#ae81ff">0.25</span>) <span style="color:#66d9ef">as</span> r:
    largest_delay<span style="color:#f92672">.</span>computet()
visualize([r, p]);

<span style="color:#75715e"># while tasks running, GIL restrict parallelism during early pd.read_csv (mostly byte ops)</span>
<span style="color:#75715e"># NOTE: diagnostics ONLY useful profiling SINGLE MACHINE - dask.distributed scheduler 8787!</span></code></pre></div>
<p><strong>SCHEDULER: (1) threaded - thread-pool, multi-processing on thread-pool; (2) serial - single-thread good for debugging; (3) distributed - multi-node or local</strong></p>

<blockquote>
<h4 id="client-default-creating-one-worker-per-core">Client() default-creating ONE WORKER PER CORE</h4>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">client <span style="color:#f92672">=</span> Client()

<span style="color:#f92672">%</span>time _ <span style="color:#f92672">=</span> largest_delay<span style="color:#f92672">.</span>compute(get<span style="color:#f92672">=</span>client<span style="color:#f92672">.</span>get)

<span style="color:#75715e"># WHY this FASTER than THREADED scheduler ??</span>
<span style="color:#75715e"># INFACT no need `get=client.get` as distributed scheduler takes over as default scheduler for all collections when Client created</span>

<span style="color:#75715e"># Locally</span>
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> LocalCluster

client <span style="color:#f92672">=</span> Client(LocalCluster(n_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>))</code></pre></div>
<blockquote>
<h3 id="cluster-creation-cluster-specific-dask-cli-available-es2-kubernetes">Cluster Creation: Cluster-specific DASK-CLI available (ES2, Kubernetes)</h3>

<h4 id="dask-worker-schedulerip-will-default-single-worker-process-with-threads-as-cores-available">dask-worker <code>schedulerIP</code> will default SINGLE WORKER PROCESS with #THREADS AS CORES AVAILABLE</h4>

<h3 id="accessing-same-dataset-among-workers">ACCESSING SAME DATASET among WORKERS</h3>

<ul>
<li>S3 storage - DASK.DF support reading directly from S3</li>
</ul>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Year&#39;</span>, etc <span style="color:#66d9ef">as</span> need]

df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;gcs://filepath/199*.csv&#39;</span>,
            parse_dates<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;Date&#39;</span>: [<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>]},
            dtype<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;col1&#39;</span>: object, <span style="color:#f92672">...</span>}
            usecols<span style="color:#f92672">=</span>columns,
            storage_options<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#e6db74">&#39;cloud&#39;</span>})</code></pre></div>
<p><strong>Persist on RAM for processing datasets</strong></p>

<ul>
<li>Bytes stored on Diagnostic Page show RAM usage</li>
<li>Fast pandas ops as IN-MEMORY</li>
<li>How large each partition? <code>df.map_partitions(pd.DataFrame.memory_usage().sum()).compute()</code></li>
</ul>

<p><strong>INDEXING is KEY</strong></p>

<blockquote>
<p>Many DF ops (loc-indexing, groupby-apply, joins) MUCH faster on sorted index; e.g. knowing WHICH part of dataset to compute, else needing to SEARCH FULL</p>

<p>Pandas model has sorted index column, Dask.df copies it and knowns min-max values of each partition&rsquo;s index (DEFAULT NO INDEX)</p>

<h4 id="however-if-setting-date-column-as-index-then-faster-calling-set-index-persist-new-set-of-df-partitions-stored-in-mem-sorted-along-index-col-dask-shuffles-data-by-date-set-index-per-partition-store-in-cluster-mem">HOWEVER: if setting <code>Date</code> column as index then FASTER - calling <code>set_index</code> + <code>persist</code> =&gt; new set of DF partitions stored IN-MEM, sorted along index col - DASK shuffles data by date, set index per partition, store in cluster-MEM</h4>

<h3 id="relatively-costly-but-gain-certain-query-speed">Relatively COSTLY - but gain certain query-speed</h3>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;Date&#39;</span>)<span style="color:#f92672">.</span>persist()

<span style="color:#75715e"># Now KNOWN Divisions !!</span>
df<span style="color:#f92672">.</span>npartiions
df<span style="color:#f92672">.</span>known_divisions <span style="color:#75715e"># True</span>
df<span style="color:#f92672">.</span>divisions <span style="color:#75715e"># output names of partitions</span>
df<span style="color:#f92672">.</span>loc[<span style="color:#e6db74">&#39;1992-05-05&#39;</span>]<span style="color:#f92672">.</span>compute() <span style="color:#75715e"># now FAST</span>
df<span style="color:#f92672">.</span>loc[<span style="color:#e6db74">&#39;1992-05-05&#39;</span>]<span style="color:#f92672">.</span>visualize(optimize_graph<span style="color:#f92672">=</span>True) <span style="color:#75715e"># only looking at single partition instead FULL SEARCH</span></code></pre></div>
<blockquote>
<h3 id="time-series-index-datetimeindex-pandas-are-supported">TIME SERIES INDEX: <code>DatetimeIndex</code> pandas are supported</h3>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline

(df<span style="color:#f92672">.</span>DepDelay
 <span style="color:#f92672">.</span>resample(<span style="color:#e6db74">&#39;1M&#39;</span>)
 <span style="color:#f92672">.</span>mean()
 <span style="color:#f92672">.</span>fillna(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ffill&#39;</span>)
 <span style="color:#f92672">.</span>compute()
 <span style="color:#f92672">.</span>plot(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">5</span>)))</code></pre></div>
<h2 id="distributed-features">DISTRIBUTED FEATURES</h2>

<ul>
<li><p><code>CLIENT.SUBMIT</code> takes (FUNC, *ARG) applying on CLUSTER -&gt; returning FUTURES representing result to be computed</p></li>

<li><p><code>repr</code> reveals &lsquo;pending&rsquo; since ASYNCHRONOUS, can do other ops while it computes (if wait until completed use <code>wait(result)</code>) - BLOCK till completed</p></li>

<li><p><code>future.result()</code> pull data out back to local disk</p></li>

<li><p><code>client.gather(future1, future2...)</code> pull back many futures</p></li>

<li><p><strong>ALTERNATIVE way to exec work on cluster - submit/map with input as future, computation moves to data rather than other way around, and client (local python session) need never see the middle values - similar to building graph by <code>delayed</code> which can be used here with futures</strong> :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> delayed(inc)(<span style="color:#ae81ff">1</span>)
total <span style="color:#f92672">=</span> delayed(add)(x, y)
  
fut <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>compute(total)
fut
fut<span style="color:#f92672">.</span>result() <span style="color:#75715e"># passing compu to cluster while freeing machine to do other works !!</span>
  
<span style="color:#75715e"># convert to submit()</span>
x <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(inc, <span style="color:#ae81ff">1</span>)
total <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(add, x, y)
  
<span style="color:#66d9ef">print</span>(total) <span style="color:#75715e"># a future</span>
total<span style="color:#f92672">.</span>result() <span style="color:#75715e"># blocks untill compu done</span></code></pre></div></li>
</ul>

<blockquote>
<h4 id="note-difference-total-compute-completes-immediately">NOTE difference: total.compute() completes immediately</h4>
</blockquote>

<ul>
<li><strong>Future API emulates map/reduce (client.map()) - middle results as futures can be passed to new tasks WITHOUT having to return to local from cluster - new work assigned using output of previous jobs not started yet !!</strong></li>
</ul>

<blockquote>
<p><strong>En general, any dask ops executed using <code>.compute()</code> can be submitted for ASYNC execution using <code>client.compute()</code> instead, applied to all collections: (here async enables continuous submission of works (perhaps based on result of calculation), or follow the progress of computation</strong></p>
</blockquote>

<pre><code>​```python
import dask.bag as db

res = (db.from_sequence(range(10))
    .map(inc)
    .filter(lambda x : x % 2 == 0)
    .sum())

f = client.compute(res)

# progress must be last line of cell to show up
progress(f)

client.gather(f)
​```
</code></pre>

<ul>
<li>Asynchronous Computation: one benefit of it enables DYNAMIC COMPUTATION adjusting as things progress (naive search by looping results as stream, submit new points to compute as others are running) USEFUL FOR PARALLEL ALGO requiring some level of SYNCHRONISATION</li>
</ul>

<h2 id="two-easy-ways-to-skl-dask">Two Easy Ways to SKL+DASK</h2>

<ol>
<li>Use Dask Joblib backend</li>

<li><p>Use dklearn projects drop-in repalcements for <code>Pipeline, GridSearchCV, RndomSearchCV</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#Joblib</span>

<span style="color:#f92672">from</span> joblib <span style="color:#f92672">import</span> parallel_backend
<span style="color:#66d9ef">with</span> parallel_backend(<span style="color:#e6db74">&#39;dask.distributed&#39;</span>, scheduler_host<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scheduler-address:8786&#39;</span>):
<span style="color:#75715e"># your now-clustered sklearn code here</span>
    
<span style="color:#75715e"># Dask-learn pipeline repalcement</span>

<span style="color:#f92672">from</span> dklearn.grid_search <span style="color:#f92672">import</span> GridSearchCV
<span style="color:#f92672">from</span> dklearn.pipeline <span style="color:#f92672">import</span> Pipeline</code></pre></div></li>
</ol>

<ul>
<li>Neither perfect - but easiest to try</li>
</ul>

<h3 id="joblib">Joblib</h3>

<ul>
<li>SKL already paral across-cores using joblib, extensible map operation</li>

<li><p>If extending Joblib to clusters then adding parallelism from joblib-enabled SKL at once</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># sequential code demo joblib</span>
<span style="color:#f92672">from</span> time <span style="color:#f92672">import</span> sleep
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">slowinc</span>(x):
sleep(<span style="color:#ae81ff">1</span>)
<span style="color:#66d9ef">return</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>

<span style="color:#f92672">%</span>timeit [slowinc(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>)]

<span style="color:#75715e"># parallel code</span>
<span style="color:#f92672">from</span> joblib <span style="color:#f92672">import</span> Parallel, delayed

<span style="color:#f92672">%</span>timeit Parallel(n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)(delayed(slowinc)(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>))</code></pre></div>
<pre><code>10 s ± 7.36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
5.03 s ± 3.65 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre></li>
</ul>

<h3 id="distributed-joblib">Distributed Joblib</h3>

<ul>
<li>API for other parallel systems to step in acting as execution engine - <code>parallel_backend</code> context manager to run with hundres or thousands of cores in nearby cluster</li>

<li><p>Main value for SKL users is that SKL already uses <code>joblib.Parallel</code> inside - e.g. <code>n_jobs</code> or using JOBLIB together with <code>Dask.distributed</code> to parallelise across multi-node cluster</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client
client <span style="color:#f92672">=</span> Client()

<span style="color:#f92672">from</span> sklearn.externals <span style="color:#f92672">import</span> joblib

<span style="color:#66d9ef">with</span> joblib<span style="color:#f92672">.</span>parallel_backend(<span style="color:#e6db74">&#39;dask&#39;</span>): <span style="color:#75715e"># scheduler_host=&#39;scheduler-address:8786&#39;):</span>
<span style="color:#66d9ef">print</span>(Parallel()(delayed(slowinc)(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> list(range(<span style="color:#ae81ff">100</span>))))</code></pre></div>
<pre><code>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">with</span> joblib<span style="color:#f92672">.</span>parallel_backend(<span style="color:#e6db74">&#39;dask&#39;</span>):
estimator <span style="color:#f92672">=</span> GridSearchCV(<span style="color:#f92672">...</span>) <span style="color:#75715e"># use joblib with Dask cluster</span></code></pre></div></li>
</ul>

<h3 id="limitations">Limitations</h3>

<ul>
<li>From Dask&rsquo;s view JL not ideal - it always collect middle results back to main process instead of leaving them on cluster until needed - still, given wide use of Joblib-enabled workflows (particularly within SKL) this is a simple thing t otry if haing cluster nearby with a possible large payoff</li>
</ul>

<h3 id="dask-learn-pipeline-and-gridsearch">Dask-Learn Pipeline and GridSearch</h3>

<ul>
<li>Dask variants of SKL Pipeline, GSCV and RandomSCV better handle nested parallelism</li>

<li><p>so if replace following imports may get both better single-threaded performance AND the ability to scale out to cluster</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># full example</span>

<span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_classification

X, y <span style="color:#f92672">=</span> make_classification(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>,
                       n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>,
                       n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
                       n_redundant<span style="color:#f92672">=</span><span style="color:#ae81ff">250</span>,
                       random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)

<span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> linear_model, decomposition
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
<span style="color:#f92672">from</span> dklearn.pipeline <span style="color:#f92672">import</span> Pipeline

logistic <span style="color:#f92672">=</span> linear_model<span style="color:#f92672">.</span>LogisticRegression()
pca <span style="color:#f92672">=</span> decomposition<span style="color:#f92672">.</span>PCA()
pipe <span style="color:#f92672">=</span> Pipeline(steps<span style="color:#f92672">=</span>[(<span style="color:#e6db74">&#39;pca&#39;</span>, pca),
                   (<span style="color:#e6db74">&#39;logistic&#39;</span>, logistic)])


<span style="color:#75715e">#Parameters of pipelines can be set using ‘__’ separated parameter names:</span>
grid <span style="color:#f92672">=</span> dict(pca__n_components<span style="color:#f92672">=</span>[<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">150</span>, <span style="color:#ae81ff">250</span>],
        logistic__C<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1e-4</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1e4</span>],
        logistic__penalty<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;l1&#39;</span>, <span style="color:#e6db74">&#39;l2&#39;</span>])

<span style="color:#75715e"># from sklearn.grid_search import GridSearchCV</span>
<span style="color:#f92672">from</span> dklearn.grid_search <span style="color:#f92672">import</span> GridSearchCV

estimator <span style="color:#f92672">=</span> GridSearchCV(pipe, grid)

estimator<span style="color:#f92672">.</span>fit(X, y)</code></pre></div></li>

<li><p>SKL performs this ~ 40s while Dask ML drop-in ~10sec, also if adding followling lines to connect to running cluster the scaling</p></li>
</ul>

<blockquote>
<p>Quickstart on Dask.distributed</p>
</blockquote>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pip install dask distributed <span style="color:#f92672">--</span>upgrade
<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client
client <span style="color:#f92672">=</span> Client() <span style="color:#75715e"># set up local cluster on machine</span>
client <span style="color:#75715e"># info on scheduler app and process/core</span>
<span style="color:#75715e"># OR setup hard way using multi-workers</span>
<span style="color:#75715e"># on shell CLI</span>
<span style="color:#960050;background-color:#1e0010">$</span> dask<span style="color:#f92672">-</span>scheduler
<span style="color:#75715e"># dask-worker 127.0.0.1:8786</span>
client <span style="color:#f92672">=</span> Client(<span style="color:#e6db74">&#39;127.0.0.1:8786&#39;</span>)
<span style="color:#75715e"># Map and Submit Func</span>
A <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(square, range(<span style="color:#ae81ff">10</span>))
B <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>map(neg, A)
total <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>submit(sum, B)
total<span style="color:#f92672">.</span>result()
<span style="color:#75715e"># Gather</span>
total <span style="color:#75715e"># function yet completed</span>
total<span style="color:#f92672">.</span>result() <span style="color:#75715e"># result for single future</span>
client<span style="color:#f92672">.</span>gather(A) <span style="color:#75715e"># gather for many futures</span>
client<span style="color:#f92672">.</span>restart() <span style="color:#75715e"># run at error</span></code></pre></div>
<h3 id="better">Better</h3>

<ul>
<li><a href="http://jcrist.github.io/dask-sklearn-part-1.html">Dask and SKL - Parallelism</a></li>
<li>Joblib + Dask.distributed is easy but leaves some speed on table - not clear how ask can help SKL codebase without being too invasive</li>
</ul>

<h2 id="convex-optimisation-algo-with-dask">Convex Optimisation Algo with Dask</h2>

<blockquote>
<p>Many ML models depend on Convex Optimisaiotn alog like Newton&rsquo;s method, SGD and others - both pgramatic and mathy - bridging math and distributed system;</p>
</blockquote>

<h3 id="prototyping-algo-in-dask">Prototyping Algo in Dask</h3>

<ul>
<li>Choices

<ol>
<li>Parallel multi-dimensional ARRAY to const algo from common ops like matrix multiplication, SVD, etc - mirroring math-algo but lacks flexibility</li>
<li>Create algo by hand tracking ops on each chunks of in-RAM data and dependencies</li>
</ol></li>
</ul>

<h3 id="example-fitting-large-lm-using-array-parallelism-and-customised-from-dask">Example - fitting large LM using array parallelism and customised from Dask</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> dask
<span style="color:#f92672">import</span> dask.array <span style="color:#f92672">as</span> da
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

<span style="color:#f92672">from</span> dask.distributed <span style="color:#f92672">import</span> Client

client <span style="color:#f92672">=</span> Client()

<span style="color:#75715e">## create inputs with a bunch of independent normals</span>
beta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(<span style="color:#ae81ff">100</span>)  <span style="color:#75715e"># random beta coefficients, no intercept</span>
X <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1000000</span>, <span style="color:#ae81ff">100</span>), chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">100000</span>, <span style="color:#ae81ff">100</span>))
y <span style="color:#f92672">=</span> X<span style="color:#f92672">.</span>dot(beta) <span style="color:#f92672">+</span> da<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000000</span>, chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">100000</span>,))

<span style="color:#75715e">## make sure all chunks are ~equally sized</span>
X, y <span style="color:#f92672">=</span> dask<span style="color:#f92672">.</span>persist(X, y)
client<span style="color:#f92672">.</span>rebalance([X, y])</code></pre></div>
<blockquote>
<p>X is dask array on 10 chunks each (100000,100) and X.dot(beta) runs smoothly for both mnumpy and dask.array, so able to write code working in either world</p>
</blockquote>

<p><strong>Caveat</strong> 0 if X is numpy array and beta is dask.array, X.dot(beta) will ouput RAM numpy array, often not desirable - FIX by <code>multipledispathch</code> to handle odd ege cases</p>

<h3 id="array-programming">Array Programming</h3>

<ul>
<li>if you can write iterative array-based algo in Numpy, then able to write iterative parallel algo in Dask</li>
<li>e.g. computing beta* from normal equation</li>
</ul>

<p><a href="http://matthewrocklin.com/blog/work/2017/03/22/dask-glm-1">FULL ARTICLE</a></p>

<h1 id="datacamp-a-id-datacamp-a">DataCamp <a id="datacamp"></a></h1>

<h1 id="working-with-big-data">Working with BIG DATA</h1>

<ul>
<li>Data &gt; one machine</li>
<li>Kilo-Mega-Giga-Tera-&hellip;

<ul>
<li>bit-2^3 (byte)&hellip;</li>
</ul></li>
</ul>

<h2 id="time-and-bit">Time and Bit</h2>

<ul>
<li>Scaled to RAM = 1s

<ul>
<li>SSD = 7-21 min</li>
<li>Rotational Disk = 2.5hr - 1day</li>
<li>Internet (SF-NY) = 3.9days</li>
</ul></li>
</ul>

<h2 id="querying-python-interpreter-s-memory-usage">Querying Python interpreter&rsquo;s Memory Usage</h2>

<ul>
<li><p>below in code as example</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> psutil<span style="color:#f92672">,</span> os

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">memory_footprint</span>():
<span style="color:#e6db74">&#39;&#39;&#39;Returns memory (MB) being used by Python process&#39;&#39;&#39;</span>
mem <span style="color:#f92672">=</span> psutil<span style="color:#f92672">.</span>Process(os<span style="color:#f92672">.</span>getpid())<span style="color:#f92672">.</span>memory_info()<span style="color:#f92672">.</span>rss
<span style="color:#66d9ef">return</span> (mem <span style="color:#f92672">/</span> <span style="color:#ae81ff">1024</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)

before <span style="color:#f92672">=</span> memory_footprint()

N <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1024</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">//</span> <span style="color:#ae81ff">8</span> <span style="color:#75715e"># Number of floats filling 1 MB</span>

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">50</span><span style="color:#f92672">*</span>N) <span style="color:#75715e"># Random array filling 50 MB</span>

after <span style="color:#f92672">=</span> memory_footprint()

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Memory before: {} MB&#39;</span><span style="color:#f92672">.</span>format(before))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Memory after: {} MB&#39;</span><span style="color:#f92672">.</span>format(after))

x<span style="color:#f92672">.</span>nbytes
x<span style="color:#f92672">.</span>nbytes <span style="color:#f92672">//</span> (<span style="color:#ae81ff">1024</span><span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)

df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(x)

df<span style="color:#f92672">.</span>memory_usage(index<span style="color:#f92672">=</span>False)</code></pre></div>
<pre><code>Memory before: 154.4765625 MB
Memory after: 204.66015625 MB
</code></pre>

<pre><code>52428800
</code></pre>

<pre><code>50
</code></pre>

<pre><code>0    52428800
dtype: int64
</code></pre></li>
</ul>

<h2 id="think-data-in-chunks">Think data in CHUNKs</h2>

<ul>
<li>Load and preprocess (filter etc) in chunks</li>

<li><p>Memory used per chunk sequentially at a time</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Filtering WDI data in chunks</span>

<span style="color:#75715e"># Load CSV from zip url using requests, zipfile, io libraries !!</span>

<span style="color:#f92672">import</span> requests<span style="color:#f92672">,</span> zipfile<span style="color:#f92672">,</span> io

dfs <span style="color:#f92672">=</span> []

req <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;https://assets.datacamp.com/production/course_4299/datasets/WDI.zip&#39;</span>)
zip <span style="color:#f92672">=</span> zipfile<span style="color:#f92672">.</span>ZipFile(io<span style="color:#f92672">.</span>BytesIO(req<span style="color:#f92672">.</span>content))
zip<span style="color:#f92672">.</span>filelist

<span style="color:#75715e"># filter in chunks then concatenate as one df</span>
<span style="color:#66d9ef">for</span> chunk <span style="color:#f92672">in</span> pd<span style="color:#f92672">.</span>read_csv(zip<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#39;WDI.csv&#39;</span>), chunksize<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
is_urban <span style="color:#f92672">=</span> chunk[<span style="color:#e6db74">&#39;Indicator Name&#39;</span>]<span style="color:#f92672">==</span><span style="color:#e6db74">&#39;Urban population (</span><span style="color:#e6db74">% o</span><span style="color:#e6db74">f total)&#39;</span>
is_AUS <span style="color:#f92672">=</span> chunk[<span style="color:#e6db74">&#39;Country Code&#39;</span>]<span style="color:#f92672">==</span><span style="color:#e6db74">&#39;AUS&#39;</span>
filtered <span style="color:#f92672">=</span> chunk<span style="color:#f92672">.</span>loc[is_urban <span style="color:#f92672">&amp;</span> is_AUS]
dfs<span style="color:#f92672">.</span>append(filtered)
pd<span style="color:#f92672">.</span>concat(dfs)</code></pre></div>
<pre><code>[&lt;ZipInfo filename='WDI.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=10590570 compress_size=1140029&gt;,
&lt;ZipInfo filename='__MACOSX/' filemode='drwxrwxr-x' external_attr=0x4000&gt;,
&lt;ZipInfo filename='__MACOSX/._WDI.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=526 compress_size=326&gt;]
</code></pre></li>
</ul>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country Name</th>
      <th>Country Code</th>
      <th>Indicator Name</th>
      <th>Indicator Code</th>
      <th>Year</th>
      <th>value</th>
      <th>Region</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>875</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1980</td>
      <td>85.760</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>950</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1981</td>
      <td>85.700</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1026</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1982</td>
      <td>85.640</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1101</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1983</td>
      <td>85.580</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1176</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1984</td>
      <td>85.520</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1251</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1985</td>
      <td>85.460</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1328</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1986</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1404</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1987</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1479</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1988</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1554</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1989</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1640</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1990</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1717</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1991</td>
      <td>85.400</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1796</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1992</td>
      <td>85.566</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1873</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1993</td>
      <td>85.748</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>1950</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1994</td>
      <td>85.928</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2029</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1995</td>
      <td>86.106</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2107</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1996</td>
      <td>86.283</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2186</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1997</td>
      <td>86.504</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2264</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1998</td>
      <td>86.727</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2341</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>1999</td>
      <td>86.947</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2428</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2000</td>
      <td>87.165</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2506</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2001</td>
      <td>87.378</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2591</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2002</td>
      <td>87.541</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2671</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2003</td>
      <td>87.695</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2752</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2004</td>
      <td>87.849</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2834</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2005</td>
      <td>88.000</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>2918</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2006</td>
      <td>88.150</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3001</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2007</td>
      <td>88.298</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3085</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2008</td>
      <td>88.445</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3168</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2009</td>
      <td>88.590</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3259</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2010</td>
      <td>88.733</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3339</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2011</td>
      <td>88.875</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3420</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2012</td>
      <td>89.015</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3499</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2013</td>
      <td>89.153</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3575</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2014</td>
      <td>89.289</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
    <tr>
      <th>3640</th>
      <td>Australia</td>
      <td>AUS</td>
      <td>Urban population (% of total)</td>
      <td>SP.URB.TOTL.IN.ZS</td>
      <td>2015</td>
      <td>89.423</td>
      <td>East Asia &amp; Pacific</td>
    </tr>
  </tbody>
</table>

</div>

<h3 id="managing-data-with-generators">Managing Data with Generators</h3>

<ul>
<li>def filter function</li>

<li><p>apply using list_comprehension</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-chunks = [filter_func(chunk) for chunk in pd.read_csv(filename, chunksize=1000)]```" data-lang="chunks = [filter_func(chunk) for chunk in pd.read_csv(filename, chunksize=1000)]```">- Instead of list-comp, lazy evaluation method of generator saves memory</code></pre></div>
<p>chunks = (filter_func(chunk) for chunk in pd.read_csv(filename, chunksize=1000))```</p>

<pre><code>- yield on run, one at a time
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sum = (chunk['feature'].sum() for chunk in chunks)" data-lang="sum = (chunk['feature'].sum() for chunk in chunks)">sum(sum)```
- only when used will gen

### Load multiple files via Generator

```template = &#39;filename_2015-{:02d}.csv&#39;```
- string formating expression
```filenames = (template.format(k) for k in range(1,13))```
- each item in filenames now yield &#39;names containing date from 01 to 12&#39;


```python
# Read multiple files in zip

req = requests.get(&#39;https://assets.datacamp.com/production/course_4299/datasets/flightdelays.zip&#39;, stream=True)
zip = zipfile.ZipFile(io.BytesIO(req.content))
zip.namelist</code></pre></div>
<pre><code>[&lt;ZipInfo filename='flightdelays/' filemode='drwxr-xr-x' external_attr=0x4000&gt;,
&lt;ZipInfo filename='flightdelays/flightdelays-2016-4.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=10901697 compress_size=1737653&gt;,
&lt;ZipInfo filename='__MACOSX/' filemode='drwxrwxr-x' external_attr=0x4000&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/' filemode='drwxrwxr-x' external_attr=0x4000&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/._flightdelays-2016-4.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2083 compress_size=1451&gt;,
&lt;ZipInfo filename='flightdelays/flightdelays-2016-5.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=11342052 compress_size=1820857&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/._flightdelays-2016-5.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2083 compress_size=1451&gt;,
&lt;ZipInfo filename='flightdelays/flightdelays-2016-2.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=10014549 compress_size=1601161&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/._flightdelays-2016-2.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2083 compress_size=1451&gt;,
&lt;ZipInfo filename='flightdelays/flightdelays-2016-3.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=11357646 compress_size=1835871&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/._flightdelays-2016-3.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2083 compress_size=1451&gt;,
&lt;ZipInfo filename='flightdelays/flightdelays-2016-1.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=10546302 compress_size=1699366&gt;,
&lt;ZipInfo filename='__MACOSX/flightdelays/._flightdelays-2016-1.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2083 compress_size=1451&gt;]
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Flight delay case</span>

<span style="color:#75715e"># func for % delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">pct_delayed</span>(df):
n_delayed <span style="color:#f92672">=</span> (df[<span style="color:#e6db74">&#39;DEP_DELAY&#39;</span>]<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>sum() 
<span style="color:#66d9ef">return</span> n_delayed  <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">/</span> (len(df))

<span style="color:#75715e"># Make file-list from above zip object</span>
filenames <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;flightdelays/flightdelays-2016-{:01d}.csv&#39;</span><span style="color:#f92672">.</span>format(k) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">6</span>)]

dataframes <span style="color:#f92672">=</span> (pd<span style="color:#f92672">.</span>read_csv(zip<span style="color:#f92672">.</span>open(file)) <span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> filenames)

monthly_delayed <span style="color:#f92672">=</span> [pct_delayed(df) <span style="color:#66d9ef">for</span> df <span style="color:#f92672">in</span> dataframes]</code></pre></div></li>
</ul>

<h2 id="generator-for-delaying-computing-and-saving-memory-usage-dask-to-simplify">Generator for delaying computing and saving memory usage: DASK to simplify</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> dask.delayed <span style="color:#f92672">import</span> delayed

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">func</span>(x):
    <span style="color:#66d9ef">return</span> sqrt(x <span style="color:#f92672">+</span> <span style="color:#ae81ff">4</span>)

func <span style="color:#f92672">=</span> delayed(func)

type(func)

<span style="color:#75715e"># using Decorator @ to combine above 2 cells</span>
<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">func</span>(x):
    <span style="color:#66d9ef">return</span> sqrt(x<span style="color:#f92672">+</span><span style="color:#ae81ff">4</span>)

type(func)</code></pre></div>
<pre><code>dask.delayed.DelayedLeaf
</code></pre>

<pre><code>dask.delayed.DelayedLeaf
</code></pre>

<h2 id="visualising-complex-dependency-loops-computations">Visualising complex dependency loops / computations</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Make 3 @delayed func</span>

<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">increment</span>(x):
    <span style="color:#66d9ef">return</span> x<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">double</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>x
<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add</span>(x,y):
    <span style="color:#66d9ef">return</span> x<span style="color:#f92672">+</span>y

data <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]

output <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> data:
    a <span style="color:#f92672">=</span> increment(x)
    b <span style="color:#f92672">=</span> double(x)
    c <span style="color:#f92672">=</span> add(a,b)
    output<span style="color:#f92672">.</span>append(c)

total <span style="color:#f92672">=</span> sum(output)

total
output

total<span style="color:#f92672">.</span>visualize()</code></pre></div>
<pre><code>Delayed('add-58eba218d09a0bd7b2482817167c0184')
</code></pre>

<pre><code>[Delayed('add-9715190e-f684-4214-9062-707a45773e27'),
 Delayed('add-c4e48f00-0a10-4da9-a9ff-453d8867d781'),
 Delayed('add-0506bbf8-17c2-4960-9e51-376de9fbaefc'),
 Delayed('add-c26bf38a-c1c2-4015-86ac-6984dd2c58e6'),
 Delayed('add-7c1f8287-53bb-4951-97b4-106bf3445149')]
</code></pre>

<p><img src="/Users/Ocean/Desktop/DASK/output_37_2.png" alt="png" /></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Request zip file URL</span>
req <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;https://assets.datacamp.com/production/course_4299/datasets/nyctaxi.zip&#39;</span>, stream<span style="color:#f92672">=</span>True)
zip <span style="color:#f92672">=</span> zipfile<span style="color:#f92672">.</span>ZipFile(io<span style="color:#f92672">.</span>BytesIO(req<span style="color:#f92672">.</span>content))
zip<span style="color:#f92672">.</span>filelist</code></pre></div>
<pre><code>[&lt;ZipInfo filename='nyctaxi/' filemode='drwxr-xr-x' external_attr=0x4000&gt;,
 &lt;ZipInfo filename='nyctaxi/yellow_tripdata_2015-03.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=9755811 compress_size=2598820&gt;,
 &lt;ZipInfo filename='__MACOSX/' filemode='drwxrwxr-x' external_attr=0x4000&gt;,
 &lt;ZipInfo filename='__MACOSX/nyctaxi/' filemode='drwxrwxr-x' external_attr=0x4000&gt;,
 &lt;ZipInfo filename='__MACOSX/nyctaxi/._yellow_tripdata_2015-03.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2091 compress_size=1449&gt;,
 &lt;ZipInfo filename='nyctaxi/.DS_Store' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=6148 compress_size=178&gt;,
 &lt;ZipInfo filename='__MACOSX/nyctaxi/._.DS_Store' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=120 compress_size=53&gt;,
 &lt;ZipInfo filename='nyctaxi/yellow_tripdata_2015-02.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=9983787 compress_size=2633156&gt;,
 &lt;ZipInfo filename='__MACOSX/nyctaxi/._yellow_tripdata_2015-02.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=2091 compress_size=1450&gt;,
 &lt;ZipInfo filename='nyctaxi/yellow_tripdata_2015-01.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=12480085 compress_size=3377085&gt;,
 &lt;ZipInfo filename='__MACOSX/nyctaxi/._yellow_tripdata_2015-01.csv' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=572 compress_size=335&gt;]
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Example using cab delay data</span>

filenames_cab <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;nyctaxi/yellow_tripdata_2015-{:02d}.csv&#39;</span><span style="color:#f92672">.</span>format(k) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">4</span>)]

<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">long_trips</span>(df):
    df[<span style="color:#e6db74">&#39;duration&#39;</span>] <span style="color:#f92672">=</span> (df<span style="color:#f92672">.</span>tpep_dropoff_datetime <span style="color:#f92672">-</span> df<span style="color:#f92672">.</span>tpep_pickup_datetime)<span style="color:#f92672">.</span>dt<span style="color:#f92672">.</span>seconds
    is_long_trip <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>duration <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1200</span>
    result_dict <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;n_long&#39;</span>:[sum(is_long_trip)],
                  <span style="color:#e6db74">&#39;n_total&#39;</span>:[len(df)]}
    <span style="color:#66d9ef">return</span> pd<span style="color:#f92672">.</span>DataFrame(result_dict)

<span style="color:#a6e22e">@delayed</span>
<span style="color:#75715e"># RECALL to add zip.open() in this case for URL</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_file</span>(fname):
    <span style="color:#66d9ef">return</span> pd<span style="color:#f92672">.</span>read_csv(zip<span style="color:#f92672">.</span>open(fname), parse_dates<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>])

<span style="color:#75715e"># Make Totals object combining above two func Read and Slice</span>
totals <span style="color:#f92672">=</span> [long_trips(read_file(fname)) <span style="color:#66d9ef">for</span> fname <span style="color:#f92672">in</span> filenames_cab]

annual_totals <span style="color:#f92672">=</span> sum(totals)

<span style="color:#75715e"># delayed_object.compute() ONLY called everything here !!</span>
annual_totals <span style="color:#f92672">=</span> annual_totals<span style="color:#f92672">.</span>compute() 

<span style="color:#66d9ef">print</span>(annual_totals[<span style="color:#e6db74">&#39;n_long&#39;</span>] <span style="color:#f92672">/</span> annual_totals[<span style="color:#e6db74">&#39;n_total&#39;</span>])</code></pre></div>
<pre><code>0    0.175269
dtype: float64
</code></pre>

<h2 id="dask-arrays-and-chunking">Dask Arrays and Chunking</h2>

<ul>
<li>Extending Numpy Array</li>
<li>Share many Numpy methods/attributes

<ul>
<li>shape, ndim, nbytes, dtype, size etc</li>
<li>max, min, mean, std, var, sum, prod</li>
<li>reshape, repeat, stack, flatten, transpose</li>
<li>round, real, imag, conj, dot</li>
</ul></li>
</ul>

<h3 id="dask-scheduler-auto-assign-multiple-processors-threads-concurrently-available">Dask scheduler auto-assign multiple processors/threads concurrently available !</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">a <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">10000</span>)

<span style="color:#f92672">import</span> dask.array <span style="color:#f92672">as</span> da


<span style="color:#75715e"># quick ex</span>
x <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random()
y <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>dot(x<span style="color:#f92672">.</span>T) <span style="color:#f92672">-</span> x<span style="color:#f92672">.</span>mean(axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)


<span style="color:#75715e"># Convert Numpy Array to Dask Array with chunking</span>
a_dask <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>from_array(a, chunks<span style="color:#f92672">=</span>len(a)<span style="color:#f92672">//</span><span style="color:#ae81ff">4</span>)

<span style="color:#75715e"># View DaskArray chunks</span>
a_dask<span style="color:#f92672">.</span>chunks

n_chunks <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>

chunk_size <span style="color:#f92672">=</span> len(a) <span style="color:#f92672">//</span> n_chunks

result <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

<span style="color:#75715e"># Comparing chunk size between Numpy and Dask</span>
<span style="color:#75715e"># In Numpy</span>
<span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(n_chunks):
    offset <span style="color:#f92672">=</span> k <span style="color:#f92672">*</span> chunk_size <span style="color:#75715e"># track offset explicitly</span>
    a_chunk <span style="color:#f92672">=</span> a[offset:offset <span style="color:#f92672">+</span> chunk_size] <span style="color:#75715e"># slice chunk</span>
    result <span style="color:#f92672">+=</span> a_chunk<span style="color:#f92672">.</span>sum()

<span style="color:#66d9ef">print</span>(result)</code></pre></div>
<pre><code>((2500, 2500, 2500, 2500),)
</code></pre>

<pre><code>5050.320824178792
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Redo with Dask Array</span>

result <span style="color:#f92672">=</span> a_dask<span style="color:#f92672">.</span>sum()

<span style="color:#75715e"># dask array automates slicing</span>
result 

result<span style="color:#f92672">.</span>compute()

<span style="color:#75715e"># Visualise its task-graph</span>
result<span style="color:#f92672">.</span>visualize(rankdir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;LR&#34;</span>) <span style="color:#75715e"># rankdir forces &#39;left-right horizontal layout&#39;</span></code></pre></div>
<pre><code>dask.array&lt;sum-aggregate, shape=(), dtype=float64, chunksize=()&gt;
</code></pre>

<pre><code>5050.320824178792
</code></pre>

<p><img src="/Users/Ocean/Desktop/DASK/output_42_2.png" alt="png" /></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Test timing of Array Computation with h5py file</span>

<span style="color:#f92672">import</span> h5py<span style="color:#f92672">,</span> time

<span style="color:#75715e"># req = requests.get(&#39;https://ndownloader.figshare.com/files/7024985&#39;)</span>
<span style="color:#75715e"># with open(&#39;sample.hd5f&#39;, &#39;wb&#39;) as f:</span>
<span style="color:#75715e">#     f.write(req.content)</span>
    
<span style="color:#66d9ef">with</span> h5py<span style="color:#f92672">.</span>File(<span style="color:#e6db74">&#39;texas.hdf5&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> dset:
    list(dset<span style="color:#f92672">.</span>keys())
    dist <span style="color:#f92672">=</span> dset[<span style="color:#e6db74">&#39;load&#39;</span>][:]
    
dist_dask8 <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>from_array(dist, chunks<span style="color:#f92672">=</span>dist<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">//</span><span style="color:#ae81ff">8</span>)

<span style="color:#75715e"># Chaining creation to leave no gap</span>
time_start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time(); \
mean8 <span style="color:#f92672">=</span> dist_dask8<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>compute(); \
time_end <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time();

time_elapsed <span style="color:#f92672">=</span> (time_end <span style="color:#f92672">-</span> time_start) <span style="color:#f92672">*</span> <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># miliseconds</span>

<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Elapsed time: {time_elapsed} ms&#39;</span>)</code></pre></div>
<pre><code>['load']
</code></pre>

<pre><code>Elapsed time: 44.425249099731445 ms
</code></pre>

<h2 id="multi-dimension-array-wrangling-similar-to-numpy">Multi-Dimension Array Wrangling ~ similar to Numpy</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">req <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/00445/Absenteeism_at_work_AAA.zip&#39;</span>)
zip <span style="color:#f92672">=</span> zipfile<span style="color:#f92672">.</span>ZipFile(io<span style="color:#f92672">.</span>BytesIO(req<span style="color:#f92672">.</span>content))
zip<span style="color:#f92672">.</span>filelist

temp <span style="color:#f92672">=</span> zip<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#39;Absenteeism_at_work.csv&#39;</span>)
temp</code></pre></div>
<pre><code>[&lt;ZipInfo filename='Absenteeism_at_work.arff' compress_type=deflate external_attr=0x20 file_size=91190 compress_size=8478&gt;,
 &lt;ZipInfo filename='Absenteeism_at_work.csv' compress_type=deflate external_attr=0x20 file_size=45232 compress_size=6822&gt;,
 &lt;ZipInfo filename='Absenteeism_at_work.xls' compress_type=deflate external_attr=0x20 file_size=141824 compress_size=17245&gt;,
 &lt;ZipInfo filename='Attribute Information.docx' compress_type=deflate external_attr=0x20 file_size=13429 compress_size=10719&gt;,
 &lt;ZipInfo filename='UCI_ABS_TEXT.docx' compress_type=deflate external_attr=0x20 file_size=44114 compress_size=22064&gt;]
</code></pre>

<pre><code>&lt;zipfile.ZipExtFile name='Absenteeism_at_work.csv' mode='r' compress_type=deflate&gt;
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Load csv into Numpy</span>

data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>loadtxt(zip<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#39;Absenteeism_at_work.csv&#39;</span>), delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;;&#39;</span>, skiprows<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, usecols<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int64)

data<span style="color:#f92672">.</span>shape
type(data)</code></pre></div>
<pre><code>(740, 4)
</code></pre>

<pre><code>numpy.ndarray
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data_dask <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>from_array(data, chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">740</span>,<span style="color:#ae81ff">2</span>))

result <span style="color:#f92672">=</span> data_dask<span style="color:#f92672">.</span>std(axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

result<span style="color:#f92672">.</span>compute() <span style="color:#75715e"># deferred computation call</span></code></pre></div>
<pre><code>array([8.42770571, 3.43396433, 1.42071379, 1.11107957])
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Read hdf5 file into Numpy</span>
electricity <span style="color:#f92672">=</span> h5py<span style="color:#f92672">.</span>File(<span style="color:#e6db74">&#39;texas.hdf5&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>)
electricity <span style="color:#f92672">=</span> electricity[<span style="color:#e6db74">&#39;load&#39;</span>][:]

type(electricity)
electricity<span style="color:#f92672">.</span>shape</code></pre></div>
<pre><code>numpy.ndarray
</code></pre>

<pre><code>(35136,)
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># This time-series array is flat comprising 3 years of grid data in 15-min interval</span>
<span style="color:#75715e"># Converting to multi-array as (year, day, 15-min)</span>
electricity_3d <span style="color:#f92672">=</span> electricity<span style="color:#f92672">.</span>reshape((<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">365</span>))</code></pre></div>
<pre><code>---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-118-b62cc72f6543&gt; in &lt;module&gt;
      1 # This time-series array is flat comprising 3 years of grid data in 15-min interval
      2 # Converting to multi-array as (year, day, 15-min)
----&gt; 3 electricity_3d = electricity.reshape((1, 365))
</code></pre>

<pre><code>ValueError: cannot reshape array of size 35136 into shape (1,365)
</code></pre>

<h3 id="wrangling-with-arrays">Wrangling with Arrays</h3>

<ul>
<li>array.reshape((d1,d2,d3)) in the context of data</li>
<li>array algebra <strong>along specific dimension</strong></li>
<li>e.g. max number of 2nd and 3rd dimension <code>array.max(axis=(1,2))</code></li>
</ul>

<h4 id="sample-code">Sample Code</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Import h5py and dask.array</span>
<span style="color:#f92672">import</span> h5py
<span style="color:#f92672">import</span> dask.array

<span style="color:#75715e"># List comprehension to read each file: dsets</span>
dsets <span style="color:#f92672">=</span> [h5py<span style="color:#f92672">.</span>File(f)[<span style="color:#e6db74">&#39;tmax&#39;</span>] <span style="color:#66d9ef">for</span> f <span style="color:#f92672">in</span> filenames]

<span style="color:#75715e"># List comprehension to make dask arrays: monthly</span>
monthly <span style="color:#f92672">=</span> [dask<span style="color:#f92672">.</span>array<span style="color:#f92672">.</span>from_array(d, chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">444</span>,<span style="color:#ae81ff">922</span>)) <span style="color:#66d9ef">for</span> d <span style="color:#f92672">in</span> dsets]</code></pre></div>
<ul>
<li>monthly comprises 4 solitary dask.array with original shape (12,444,922) chunked by (1,444,922), equating to 12 chunks per dask.array</li>

<li><p>Then to <strong>STACK</strong> them as one <code>dask.stack(array, axis=0)</code> row-wise ! Resulting dimension is (4, 12, 444, 922) in total and chunked as 4x12 (1,1,444,922)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Stack with the list of dask arrays: by_year</span>
by_year <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>stack(monthly, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

<span style="color:#75715e"># Print the shape of the stacked arrays</span>
<span style="color:#66d9ef">print</span>(by_year<span style="color:#f92672">.</span>shape)

<span style="color:#75715e"># Read the climatology data: climatology</span>
dset <span style="color:#f92672">=</span> h5py<span style="color:#f92672">.</span>File(<span style="color:#e6db74">&#39;tmax.climate.hdf5&#39;</span>)
climatology <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>from_array(dset[<span style="color:#e6db74">&#39;/tmax&#39;</span>], chunks<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">444</span>,<span style="color:#ae81ff">922</span>))

<span style="color:#75715e"># Reshape the climatology data to be compatible with months</span>
climatology <span style="color:#f92672">=</span> climatology<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">444</span>,<span style="color:#ae81ff">922</span>)</code></pre></div></li>

<li><p>Further slicing with dask.array.nanmean() function ignoring missing value</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Compute the difference: diff</span>
diff <span style="color:#f92672">=</span> (by_year<span style="color:#f92672">-</span>climatology)<span style="color:#f92672">*</span><span style="color:#ae81ff">9</span><span style="color:#f92672">/</span><span style="color:#ae81ff">5</span>
<span style="color:#75715e"># Compute the average over last two axes: avg</span>
avg <span style="color:#f92672">=</span> da<span style="color:#f92672">.</span>nanmean(diff, axis<span style="color:#f92672">=</span>(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>))<span style="color:#f92672">.</span>compute()
<span style="color:#75715e"># Plot the slices [:,0], [:,7], and [:11] against the x values</span>
x <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">2008</span>,<span style="color:#ae81ff">2012</span>)
f, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots()
ax<span style="color:#f92672">.</span>plot(x,avg[:,<span style="color:#ae81ff">0</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Jan&#39;</span>)
ax<span style="color:#f92672">.</span>plot(x,avg[:,<span style="color:#ae81ff">7</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Aug&#39;</span>)
ax<span style="color:#f92672">.</span>plot(x,avg[:,<span style="color:#ae81ff">11</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Dec&#39;</span>)
ax<span style="color:#f92672">.</span>axhline(<span style="color:#ae81ff">0</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>)
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Year&#39;</span>)
ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Difference (degrees Fahrenheit)&#39;</span>)
ax<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
plt<span style="color:#f92672">.</span>show()</code></pre></div></li>
</ul>

<h2 id="dask-dataframe-pandas-df">Dask DataFrame ~ Pandas DF</h2>

<ul>
<li>dask.dataframe as dd</li>

<li><p><strong>High-level Scalable Pandas DF</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Using WDI csv dataset</span>
<span style="color:#f92672">import</span> dask.dataframe <span style="color:#f92672">as</span> dd

req <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;https://assets.datacamp.com/production/course_4299/datasets/WDI.zip&#39;</span>)
zip <span style="color:#f92672">=</span> zipfile<span style="color:#f92672">.</span>ZipFile(io<span style="color:#f92672">.</span>BytesIO(req<span style="color:#f92672">.</span>content))
zip<span style="color:#f92672">.</span>NameToInfo

df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(zip<span style="color:#f92672">.</span>extract(<span style="color:#e6db74">&#39;WDI.csv&#39;</span>))
df<span style="color:#f92672">.</span>head()

df<span style="color:#f92672">.</span>groupby(df<span style="color:#f92672">.</span>name)<span style="color:#f92672">.</span>value<span style="color:#f92672">.</span>mean()</code></pre></div>
<pre><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-1-3e3642d3fe4c&gt; in &lt;module&gt;
  2 import dask.dataframe as dd
  3 
----&gt; 4 req = requests.get('https://assets.datacamp.com/production/course_4299/datasets/WDI.zip')
  5 zip = zipfile.ZipFile(io.BytesIO(req.content))
  6 zip.NameToInfo
</code></pre>

<pre><code>NameError: name 'requests' is not defined
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Boolean series where &#39;Indicator Code&#39; is &#39;EN.ATM.PM25.MC.ZS&#39;: toxins</span>
toxins <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Indicator Code&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;AG.LND.TRAC.ZS&#39;</span>
<span style="color:#75715e"># Boolean series where &#39;Region&#39; is &#39;East Asia &amp; Pacific&#39;: region</span>
region <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Region&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;East Asia &amp; Pacific&#39;</span>

<span style="color:#75715e"># Filter the DataFrame using toxins &amp; region: filtered</span>
filtered <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>loc[toxins <span style="color:#f92672">&amp;</span> region]

<span style="color:#75715e"># Groupby and Compute mean</span>
yearly_mean <span style="color:#f92672">=</span> filtered<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;Year&#39;</span>)<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>compute()

yearly_mean[<span style="color:#e6db74">&#39;value&#39;</span>]<span style="color:#f92672">.</span>plot<span style="color:#f92672">.</span>line()
plt<span style="color:#f92672">.</span>show()</code></pre></div>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1763ae4e80&gt;
</code></pre></li>
</ul>

<p><img src="/Users/Ocean/Desktop/DASK/output_53_1.png" alt="png" /></p>

<h2 id="timing-dask-df-loading-and-computation">Timing Dask DF Loading and Computation</h2>

<ul>
<li>Quick example of 12 2GB files loading and averaging reveals Dask DF takes about 3min at compute call, which Pandas loading 1 file 43s</li>
</ul>

<h4 id="decision-to-both-largely-depends-on-whehter">Decision to both largely depends on whehter</h4>

<ol>
<li>Data size fit into I/O (disk) and/or CPU (RAM)</li>
<li>Requires Pandas methods non-existent in Dask</li>
</ol>

<h4 id="example-analysing-full-year-taxi-tipping">Example analysing full-year taxi tipping</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Read all .csv files: df</span>
df <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;taxi/*.csv&#39;</span>, assume_missing<span style="color:#f92672">=</span>True)

<span style="color:#75715e"># Make column &#39;tip_fraction&#39;</span>
df[<span style="color:#e6db74">&#39;tip_fraction&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;tip_amount&#39;</span>] <span style="color:#f92672">/</span> (df[<span style="color:#e6db74">&#39;total_amount&#39;</span>] <span style="color:#f92672">-</span> df[<span style="color:#e6db74">&#39;tip_amount&#39;</span>])

<span style="color:#75715e"># Convert &#39;tpep_dropoff_datetime&#39; column to datetime objects</span>
df[<span style="color:#e6db74">&#39;tpep_dropoff_datetime&#39;</span>] <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>to_datetime(df[<span style="color:#e6db74">&#39;tpep_dropoff_datetime&#39;</span>])

<span style="color:#75715e"># Construct column &#39;hour&#39;</span>
df[<span style="color:#e6db74">&#39;hour&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;tpep_dropoff_datetime&#39;</span>]<span style="color:#f92672">.</span>dt<span style="color:#f92672">.</span>hour

<span style="color:#75715e"># Filter rows where payment_type == 1: credit</span>
credit <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>loc[df[<span style="color:#e6db74">&#39;payment_type&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>]

<span style="color:#75715e"># Group by &#39;hour&#39; column: hourly</span>
hourly <span style="color:#f92672">=</span> credit<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;hour&#39;</span>)

<span style="color:#75715e"># Aggregate mean &#39;tip_fraction&#39; and print its data type</span>
result <span style="color:#f92672">=</span> hourly[<span style="color:#e6db74">&#39;tip_fraction&#39;</span>]<span style="color:#f92672">.</span>mean()
<span style="color:#66d9ef">print</span>(type(result))

<span style="color:#75715e"># Perform the computation</span>
tip_frac <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>compute()

<span style="color:#75715e"># Print the type of tip_frac</span>
<span style="color:#66d9ef">print</span>(type(tip_frac))

<span style="color:#75715e"># Generate a line plot using .plot.line()</span>
tip_frac<span style="color:#f92672">.</span>plot<span style="color:#f92672">.</span>line()
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Tip fraction&#39;</span>)
plt<span style="color:#f92672">.</span>show()</code></pre></div>
<h2 id="dask-bag-and-globbing">Dask Bag and Globbing</h2>

<ul>
<li>List of nested kinds: list, dict, string, etc</li>

<li><p>Normally test file containing one \n separated text</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> glob

req <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;https://assets.datacamp.com/production/course_4299/datasets/sotu.zip&#39;</span>)
zip <span style="color:#f92672">=</span> zipfile<span style="color:#f92672">.</span>ZipFile(io<span style="color:#f92672">.</span>BytesIO(req<span style="color:#f92672">.</span>content))
zip<span style="color:#f92672">.</span>extractall()

filenames <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;sotu/*.txt&#39;</span>)
filenames <span style="color:#f92672">=</span> sorted(filenames)

<span style="color:#f92672">import</span> dask.bag <span style="color:#f92672">as</span> db

speeches <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>read_text(filenames)
<span style="color:#66d9ef">print</span>(speeches<span style="color:#f92672">.</span>count()<span style="color:#f92672">.</span>compute())</code></pre></div>
<pre><code>237
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Call .take(1): one_element</span>
one_element <span style="color:#f92672">=</span> speeches<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">1</span>)

<span style="color:#75715e"># Extract first element of one_element: first_speech</span>
first_speech <span style="color:#f92672">=</span> one_element[<span style="color:#ae81ff">0</span>]

<span style="color:#75715e"># Print type of first_speech and first 60 characters</span>
<span style="color:#66d9ef">print</span>(type(first_speech))
<span style="color:#66d9ef">print</span>(first_speech[:<span style="color:#ae81ff">61</span>])</code></pre></div>
<pre><code>&lt;class 'str'&gt;
Fellow-Citizens of the Senate and House of Representatives: 
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Call .str.split(&#39; &#39;) from speeches and assign it to by_word</span>
by_word <span style="color:#f92672">=</span> speeches<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39; &#39;</span>)

<span style="color:#75715e"># Map the len function over by_word and compute its mean</span>
n_words <span style="color:#f92672">=</span> by_word<span style="color:#f92672">.</span>map(len)
avg_words <span style="color:#f92672">=</span> n_words<span style="color:#f92672">.</span>mean()

<span style="color:#75715e"># Print the type of avg_words and value of avg_words.compute()</span>
<span style="color:#66d9ef">print</span>(type(avg_words))
<span style="color:#66d9ef">print</span>(avg_words<span style="color:#f92672">.</span>compute())

<span style="color:#75715e"># Convert speeches to lower case: lower</span>
lower <span style="color:#f92672">=</span> speeches<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>lower()

<span style="color:#75715e"># Filter lower for the presence of &#39;health care&#39;: health</span>
health <span style="color:#f92672">=</span> lower<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> s:<span style="color:#e6db74">&#39;health care&#39;</span> <span style="color:#f92672">in</span> s)

<span style="color:#75715e"># Count the number of entries : n_health</span>
n_health <span style="color:#f92672">=</span> health<span style="color:#f92672">.</span>count()

<span style="color:#75715e"># Compute and print the value of n_health</span>
<span style="color:#66d9ef">print</span>(n_health<span style="color:#f92672">.</span>compute())</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Call db.read_text with congress/bills*.json: bills_text</span>
bills_text <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>read_text(<span style="color:#e6db74">&#39;congress/bills*.json&#39;</span>)

<span style="color:#75715e"># Map the json.loads function over all elements: bills_dicts</span>
bills_dicts <span style="color:#f92672">=</span> bills_text<span style="color:#f92672">.</span>map(json<span style="color:#f92672">.</span>loads)

<span style="color:#75715e"># Extract the first element with .take(1) and index to the first position: first_bill</span>
first_bill <span style="color:#f92672">=</span> bills_dicts<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]

<span style="color:#75715e"># Print the keys of first_bill</span>
<span style="color:#66d9ef">print</span>(first_bill<span style="color:#f92672">.</span>keys())


<span style="color:#75715e"># Filter the bills: overridden</span>
overridden <span style="color:#f92672">=</span> bills_dicts<span style="color:#f92672">.</span>filter(veto_override)

<span style="color:#75715e"># Print the number of bills retained</span>
<span style="color:#66d9ef">print</span>(overridden<span style="color:#f92672">.</span>count()<span style="color:#f92672">.</span>compute())

<span style="color:#75715e"># Get the value of the &#39;title&#39; key</span>
titles <span style="color:#f92672">=</span> overridden<span style="color:#f92672">.</span>pluck(<span style="color:#e6db74">&#39;title&#39;</span>)

<span style="color:#75715e"># Compute and print the titles</span>
<span style="color:#66d9ef">print</span>(titles<span style="color:#f92672">.</span>compute())


<span style="color:#75715e"># Define a function lifespan that takes a dictionary d as input</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lifespan</span>(d):
<span style="color:#75715e"># Convert to datetime</span>
current <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>to_datetime(d[<span style="color:#e6db74">&#39;current_status_date&#39;</span>])
intro <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>to_datetime(d[<span style="color:#e6db74">&#39;introduced_date&#39;</span>])

<span style="color:#75715e"># Return the number of days</span>
<span style="color:#66d9ef">return</span> (current <span style="color:#f92672">-</span> intro)<span style="color:#f92672">.</span>days

<span style="color:#75715e"># Filter bills_dicts: days</span>
days <span style="color:#f92672">=</span> bills_dicts<span style="color:#f92672">.</span>filter(<span style="color:#66d9ef">lambda</span> s:s[<span style="color:#e6db74">&#39;current_status&#39;</span>]<span style="color:#f92672">==</span><span style="color:#e6db74">&#39;enacted_signed&#39;</span>)<span style="color:#f92672">.</span>map(lifespan)

<span style="color:#75715e"># Print the mean value of the days Bag</span>
<span style="color:#66d9ef">print</span>(days<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>compute())</code></pre></div></li>
</ul>

<h2 id="all-together-detailed-analysis">All together Detailed Analysis</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Define @delayed-function read_flights</span>
<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_flights</span>(filename):

    <span style="color:#75715e"># Read in the DataFrame: df</span>
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(filename, parse_dates<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;FL_DATE&#39;</span>])

    <span style="color:#75715e"># Replace 0s in df[&#39;WEATHER_DELAY&#39;] with np.nan</span>
    df[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>replace(<span style="color:#ae81ff">0</span>, np<span style="color:#f92672">.</span>nan)

    <span style="color:#75715e"># Return df</span>
    <span style="color:#66d9ef">return</span> df


<span style="color:#75715e"># Loop over filenames with index filename</span>
<span style="color:#66d9ef">for</span> filename <span style="color:#f92672">in</span> filenames:
    <span style="color:#75715e"># Apply read_flights to filename; append to dataframes</span>
    dataframes<span style="color:#f92672">.</span>append(read_flights(filename))

<span style="color:#75715e"># Compute flight delays: flight_delays</span>
flight_delays <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>from_delayed(dataframes)

<span style="color:#75715e"># Print average of &#39;WEATHER_DELAY&#39; column of flight_delays</span>
<span style="color:#66d9ef">print</span>(flight_delays[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>compute())


<span style="color:#75715e"># Define @delayed-function read_weather with input filename</span>
<span style="color:#a6e22e">@delayed</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_weather</span>(filename):
    <span style="color:#75715e"># Read in filename: df</span>
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(filename, parse_dates<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Date&#39;</span>])

    <span style="color:#75715e"># Clean &#39;PrecipitationIn&#39;</span>
    df[<span style="color:#e6db74">&#39;PrecipitationIn&#39;</span>] <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>to_numeric(df[<span style="color:#e6db74">&#39;PrecipitationIn&#39;</span>], errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;coerce&#39;</span>)

    <span style="color:#75715e"># Create the &#39;Airport&#39; column</span>
    df[<span style="color:#e6db74">&#39;Airport&#39;</span>] <span style="color:#f92672">=</span> filename<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#ae81ff">0</span>]

    <span style="color:#75715e"># Return df</span>
    <span style="color:#66d9ef">return</span> df



<span style="color:#75715e"># Loop over filenames with filename</span>
<span style="color:#66d9ef">for</span> filename <span style="color:#f92672">in</span> filenames:
    <span style="color:#75715e"># Invoke read_weather on filename; append resultt to weather_dfs</span>
    weather_dfs<span style="color:#f92672">.</span>append(read_weather(filename))

<span style="color:#75715e"># Call dd.from_delayed() with weather_dfs: weather</span>
weather <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>from_delayed(weather_dfs)

<span style="color:#75715e"># Print result of weather.nlargest(1, &#39;Max TemperatureF&#39;)</span>
<span style="color:#66d9ef">print</span>(weather<span style="color:#f92672">.</span>nlargest(<span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#39;Max TemperatureF&#39;</span>)<span style="color:#f92672">.</span>compute())


<span style="color:#75715e"># Make cleaned Boolean Series from weather[&#39;Events&#39;]: is_snowy</span>
is_snowy <span style="color:#f92672">=</span> weather[<span style="color:#e6db74">&#39;Events&#39;</span>]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>contains(<span style="color:#e6db74">&#39;Snow&#39;</span>)<span style="color:#f92672">.</span>fillna(False)

<span style="color:#75715e"># Create filtered DataFrame with weather.loc &amp; is_snowy: got_snow</span>
got_snow <span style="color:#f92672">=</span> weather<span style="color:#f92672">.</span>loc[is_snowy]

<span style="color:#75715e"># Groupby &#39;Airport&#39; column; select &#39;PrecipitationIn&#39;; aggregate sum(): result</span>
result <span style="color:#f92672">=</span> got_snow<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;Airport&#39;</span>)[<span style="color:#e6db74">&#39;PrecipitationIn&#39;</span>]<span style="color:#f92672">.</span>sum()

<span style="color:#75715e"># Compute &amp; print the value of result</span>
<span style="color:#66d9ef">print</span>(result<span style="color:#f92672">.</span>compute())


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">percent_delayed</span>(df):
    <span style="color:#66d9ef">return</span> (df[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>count() <span style="color:#f92672">/</span> len(df)) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>

<span style="color:#75715e"># Print time in milliseconds to compute percentage_delayed on weather_delays</span>
t_start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">print</span>(percent_delayed(weather_delays)<span style="color:#f92672">.</span>compute())
t_end <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">print</span>((t_end<span style="color:#f92672">-</span>t_start)<span style="color:#f92672">*</span><span style="color:#ae81ff">1000</span>)

<span style="color:#75715e"># Call weather_delays.persist(): persisted_weather_delays</span>
persisted_weather_delays <span style="color:#f92672">=</span> weather_delays<span style="color:#f92672">.</span>persist()

<span style="color:#75715e"># Print time in milliseconds to compute percentage_delayed on persisted_weather_delays</span>
t_start <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">print</span>(percent_delayed(persisted_weather_delays)<span style="color:#f92672">.</span>compute())
t_end <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
<span style="color:#66d9ef">print</span>((t_end<span style="color:#f92672">-</span>t_start)<span style="color:#f92672">*</span><span style="color:#ae81ff">1000</span>)



<span style="color:#75715e"># Group persisted_weather_delays by &#39;Events&#39;: by_event</span>
by_event <span style="color:#f92672">=</span> persisted_weather_delays<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;Events&#39;</span>)

<span style="color:#75715e"># Count &#39;by_event[&#39;WEATHER_DELAY&#39;] column &amp; divide by total number of delayed flights</span>
pct_delayed <span style="color:#f92672">=</span> by_event[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>count() <span style="color:#f92672">/</span> persisted_weather_delays[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>count() <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>

<span style="color:#75715e"># Compute &amp; print five largest values of pct_delayed</span>
<span style="color:#66d9ef">print</span>(pct_delayed<span style="color:#f92672">.</span>nlargest(<span style="color:#ae81ff">5</span>)<span style="color:#f92672">.</span>compute())

<span style="color:#75715e"># Calculate mean of by_event[&#39;WEATHER_DELAY&#39;] column &amp; return the 5 largest entries: avg_delay_time</span>
avg_delay_time <span style="color:#f92672">=</span> by_event[<span style="color:#e6db74">&#39;WEATHER_DELAY&#39;</span>]<span style="color:#f92672">.</span>mean()<span style="color:#f92672">.</span>nlargest(<span style="color:#ae81ff">5</span>)

<span style="color:#75715e"># Compute &amp; print avg_delay_time</span>
<span style="color:#66d9ef">print</span>(avg_delay_time<span style="color:#f92672">.</span>compute())</code></pre></div>
<h1 id="streamz-streaming-data-analysis-pythonic-with-dask-a-id-streamz-a">Streamz - Streaming Data Analysis Pythonic with Dask <a id="streamz"></a></h1>

<ol>
<li>Streamz.core

<ul>
<li>map, accumulate</li>
<li>time control and back pressure</li>
<li>jupyter integration</li>
</ul></li>
<li>Streamz.dataframe

<ul>
<li>stream of pandas df</li>
<li>with pandas API</li>
<li>plotting with Holoviews/Bokeh</li>
</ul></li>

<li><p>Streamz.dask</p>

<ul>
<li>full effecting on top of Dask</li>
<li>adds millisec overhead and 10-20ms latency</li>

<li><p>scales</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> IPython.display <span style="color:#f92672">import</span> HTML

HTML(<span style="color:#e6db74">&#39;&lt;div style=&#34;position:relative;height:0;padding-bottom:56.25%&#34;&gt;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/yI_yZoUaz60&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&#39;</span>)</code></pre></div></li>
</ul></li>
</ol>

<div style="position:relative;height:0;padding-bottom:56.25%"><iframe width="560" height="315" src="https://www.youtube.com/embed/yI_yZoUaz60" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> streamz <span style="color:#f92672">import</span> Stream

stream <span style="color:#f92672">=</span> Stream()</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">stream<span style="color:#f92672">.</span>emit(<span style="color:#ae81ff">100</span>) <span style="color:#75715e"># push data into stream BUT YET to stream data</span>

<span style="color:#75715e"># once below defined, stream becomes active with map()</span></code></pre></div>
<pre><code>101
200
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">inc</span>(x):
    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">double</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span>x

a <span style="color:#f92672">=</span> stream<span style="color:#f92672">.</span>map(inc)<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">print</span>)
b <span style="color:#f92672">=</span> stream<span style="color:#f92672">.</span>map(double)<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">print</span>)</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">stream<span style="color:#f92672">.</span>visualize()</code></pre></div>
<p><img src="/Users/Ocean/Desktop/DASK/output_68_0.png" alt="png" /></p>

<h3 id="code-to-create-random-json-data">Code to create random JSON data</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime
<span style="color:#f92672">import</span> json
<span style="color:#f92672">import</span> random

i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
record_names <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Alice&#39;</span>, <span style="color:#e6db74">&#39;Bob&#39;</span>, <span style="color:#e6db74">&#39; Charlie&#39;</span>]

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_record</span>():
    <span style="color:#66d9ef">global</span> i
    i <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
    record <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;name&#39;</span>: random<span style="color:#f92672">.</span>choice(record_names),
             <span style="color:#e6db74">&#39;i&#39;</span>: i,
             <span style="color:#e6db74">&#39;x&#39;</span>: random<span style="color:#f92672">.</span>random(),
             <span style="color:#e6db74">&#39;y&#39;</span>: random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">10</span>),
             <span style="color:#e6db74">&#39;time&#39;</span>: str(datetime<span style="color:#f92672">.</span>now())}
    <span style="color:#66d9ef">return</span> json<span style="color:#f92672">.</span>dumps(record)</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">create_record() <span style="color:#75715e"># random stream of data</span></code></pre></div>
<pre><code>'{&quot;name&quot;: &quot;Alice&quot;, &quot;i&quot;: 29, &quot;x&quot;: 0.12326123720304571, &quot;y&quot;: 2, &quot;time&quot;: &quot;2018-11-29 07:29:08.834679&quot;}'
</code></pre>

<h3 id="basic-streams-and-map">Basic Streams and Map</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">source <span style="color:#f92672">=</span> Stream()
source</code></pre></div>
<pre><code>Output()
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># create stream of json-parsed records</span>
records <span style="color:#f92672">=</span> source<span style="color:#f92672">.</span>map(json<span style="color:#f92672">.</span>loads)
records</code></pre></div>
<pre><code>Output()
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># create stream of names</span>
names <span style="color:#f92672">=</span> records<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> d: d[<span style="color:#e6db74">&#39;name&#39;</span>])
names</code></pre></div>
<pre><code>Output()
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># push data into stream</span>
source<span style="color:#f92672">.</span>emit(create_record())</code></pre></div>
<pre><code>{'name': 'Bob',
 'i': 39,
 'x': 0.417140916688034,
 'y': 1,
 'time': '2018-11-29 07:30:16.494038'}
</code></pre>

<h2 id="async-computation">Async Computation</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> tornado <span style="color:#f92672">import</span> gen
<span style="color:#f92672">import</span> time

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">increment</span>(x):
    <span style="color:#e6db74">&#34;&#34;&#34; A blocking increment function
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    Simulates a computational function that was not designed to work
</span><span style="color:#e6db74">    asynchronously
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">0.1</span>)
    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>

<span style="color:#a6e22e">@gen.coroutine</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">write</span>(x):
    <span style="color:#e6db74">&#34;&#34;&#34; A non-blocking write function
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    Simulates writing to a database asynchronously
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">yield</span> gen<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">0.2</span>)
    <span style="color:#66d9ef">print</span>(x)</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Within Event Loop: e.g. an app running strictly within event loop</span>

<span style="color:#f92672">from</span> streamz <span style="color:#f92672">import</span> Stream
<span style="color:#f92672">from</span> tornado.ioloop <span style="color:#f92672">import</span> IOLoop

async <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
    source <span style="color:#f92672">=</span> Stream(asynchronous<span style="color:#f92672">=</span>True)  <span style="color:#75715e"># tell the stream we&#39;re working asynchronously</span>
    source<span style="color:#f92672">.</span>map(increment)<span style="color:#f92672">.</span>rate_limit(<span style="color:#ae81ff">0.500</span>)<span style="color:#f92672">.</span>sink(write)

    <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
        await source<span style="color:#f92672">.</span>emit(x)

IOLoop()<span style="color:#f92672">.</span>run_sync(f)</code></pre></div>
<pre><code>---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-97-3b7d97fa315e&gt; in &lt;module&gt;
     11         await source.emit(x)
     12 
---&gt; 13 IOLoop().run_sync(f)
</code></pre>

<pre><code>/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py in run_sync(self, func, timeout)
    569                     self.stop()
    570             timeout_handle = self.add_timeout(self.time() + timeout, timeout_callback)
--&gt; 571         self.start()
    572         if timeout is not None:
    573             self.remove_timeout(timeout_handle)
</code></pre>

<pre><code>/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py in start(self)
    130             self._setup_logging()
    131             asyncio.set_event_loop(self.asyncio_loop)
--&gt; 132             self.asyncio_loop.run_forever()
    133         finally:
    134             asyncio.set_event_loop(old_loop)
</code></pre>

<pre><code>/usr/lib/python3.6/asyncio/base_events.py in run_forever(self)
    410         if events._get_running_loop() is not None:
    411             raise RuntimeError(
--&gt; 412                 'Cannot run the event loop while another loop is running')
    413         self._set_coroutine_wrapper(self._debug)
    414         self._thread_id = threading.get_ident()
</code></pre>

<pre><code>RuntimeError: Cannot run the event loop while another loop is running
</code></pre>

<h3 id="mock-continous-updates">Mock Continous updates</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> tornado <span style="color:#f92672">import</span> gen
<span style="color:#f92672">from</span> tornado.ioloop <span style="color:#f92672">import</span> IOLoop

async <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>():
    <span style="color:#66d9ef">while</span> True:
        await gen<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">0.5</span>)
        await source<span style="color:#f92672">.</span>emit(create_record(), asynchronous<span style="color:#f92672">=</span>True)
        
IOLoop<span style="color:#f92672">.</span>current()<span style="color:#f92672">.</span>add_callback(f)</code></pre></div>
<pre><code>'Alice'
</code></pre>

<pre><code>tornado.application - ERROR - Exception in callback functools.partial(&lt;function wrap.&lt;locals&gt;.null_wrapper at 0x7ff9640da158&gt;, &lt;Task finished coro=&lt;f() done, defined at &lt;ipython-input-78-8a3fd1b15f3b&gt;:4&gt; exception=TypeError(&quot;object NoneType can't be used in 'await' expression&quot;,)&gt;)
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py&quot;, line 758, in _run_callback
    ret = callback()
  File &quot;/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py&quot;, line 300, in null_wrapper
    return fn(*args, **kwargs)
  File &quot;/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py&quot;, line 779, in _discard_future_result
    future.result()
  File &quot;&lt;ipython-input-78-8a3fd1b15f3b&gt;&quot;, line 7, in f
    await source.emit(create_record(), asynchronous=True)
TypeError: object NoneType can't be used in 'await' expression
</code></pre>

<h3 id="accumulators">Accumulators</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Sum &#39;x&#39; over time</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">binop</span>(totla, new):
    <span style="color:#66d9ef">return</span> total <span style="color:#f92672">+</span> new

records<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> d: d[<span style="color:#e6db74">&#39;x&#39;</span>])<span style="color:#f92672">.</span>accumulate(binop, start<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)</code></pre></div>
<pre><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-24-b9420dfdd9c4&gt; in &lt;module&gt;
      4     return total + new
      5 
----&gt; 6 records.map(lambda d: d['x']).accumulate(binop, start=0)
</code></pre>

<pre><code>NameError: name 'records' is not defined
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Count occurences of names over time</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accumulator</span>(acc, new):
    acc <span style="color:#f92672">=</span> acc<span style="color:#f92672">.</span>copy()
    <span style="color:#66d9ef">if</span> new <span style="color:#f92672">in</span> acc:
        acc[new] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        acc[new] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">return</span> acc

names<span style="color:#f92672">.</span>accumulate(accumulator, start<span style="color:#f92672">=</span>{})</code></pre></div>
<pre><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-25-10c5c3797b77&gt; in &lt;module&gt;
      9     return acc
     10 
---&gt; 11 names.accumulate(accumulator, start={})
</code></pre>

<pre><code>NameError: name 'names' is not defined
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"></code></pre></div>
<h1 id="streaming-bokeh-server">Streaming + Bokeh Server</h1>

<ul>
<li>bokeh&rsquo;s true value is serving live-streaming, interactive visual updating real-time data</li>
<li><a href="https://distributed.readthedocs.io/en/latest/web.html">dignostics for distributed system</a></li>
</ul>

<h3 id="launch-bokeh-servers-from-notebook">Launch Bokeh Servers from Notebook</h3>

<ul>
<li>Make func which is called when site visited - whatever it wants, here a simple line plot with doc.add_root() method</li>

<li><p>This starts a Tornado web server creating new image whenever connected, similar to lib in Tornado or Flask - in this case piggybacks on Jupyter own IOLoop because Bokeh is built on Tornado it can play nicely with other <strong>async</strong> apps like Tornado or Asyncio</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> bokeh.server.server <span style="color:#f92672">import</span> Server
<span style="color:#f92672">from</span> bokeh.application <span style="color:#f92672">import</span> Application
<span style="color:#f92672">from</span> bokeh.application.handlers.function <span style="color:#f92672">import</span> FunctionHandler
<span style="color:#f92672">from</span> bokeh.plotting <span style="color:#f92672">import</span> figure, ColumnDataSource

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">make_document</span>(doc):
fig <span style="color:#f92672">=</span> figure(title<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Line plot&#39;</span>, sizing_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale_width&#39;</span>)
fig<span style="color:#f92672">.</span>line(x<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>], y<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">9</span>])
    
doc<span style="color:#f92672">.</span>title <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Hellow, world!&#34;</span>
doc<span style="color:#f92672">.</span>add_root(fig)
    
apps <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;/&#39;</span>: Application(FunctionHandler(make_document))}

server <span style="color:#f92672">=</span> Server(apps, port<span style="color:#f92672">=</span><span style="color:#ae81ff">5000</span>)
server<span style="color:#f92672">.</span>start()</code></pre></div></li>
</ul>

<h3 id="live-updates">Live Updates</h3>

<ul>
<li>Doing live visual often means serialising data on server, figuring out how web sockets work, sending data to client/browser and then updating plots in browser</li>
<li>Bokeh handles this by keeping a <strong>synchronised</strong> table of data on client and the server, the <code>ColumnDataSource</code>.</li>
<li>If defining plots around column data source then pushing more data into source, Bokeh will handle the rest - updating plots in broswer just needs pushing more data into object on server</li>
<li>Below, make new object upding func adding new record, set up callback to call func every 100ms the graph</li>
<li>Changing figures (or adding multiple figures, text, or visual elements, etc) full freedom over visual styling</li>

<li><p>Changing around update func can pull data from sensors, shove in more data etc</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> random

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">make_document</span>(doc):
source <span style="color:#f92672">=</span> ColumnDataSource({<span style="color:#e6db74">&#39;x&#39;</span>: [], <span style="color:#e6db74">&#39;y&#39;</span>: [], <span style="color:#e6db74">&#39;color&#39;</span>: []})

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update</span>():
    new <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;x&#39;</span>: [random<span style="color:#f92672">.</span>random()],
           <span style="color:#e6db74">&#39;y&#39;</span>: [random<span style="color:#f92672">.</span>random()],
           <span style="color:#e6db74">&#39;color&#39;</span>: [random<span style="color:#f92672">.</span>choice([<span style="color:#e6db74">&#39;red&#39;</span>, <span style="color:#e6db74">&#39;blue&#39;</span>, <span style="color:#e6db74">&#39;green&#39;</span>])]}
    source<span style="color:#f92672">.</span>stream(new)

doc<span style="color:#f92672">.</span>add_periodic_callback(update, <span style="color:#ae81ff">100</span>)

fig <span style="color:#f92672">=</span> figure(title<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Streaming Circle Plot!&#39;</span>, sizing_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;scale_width&#39;</span>,
             x_range<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], y_range<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>])
fig<span style="color:#f92672">.</span>circle(source<span style="color:#f92672">=</span>source, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;x&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;y&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;color&#39;</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)

doc<span style="color:#f92672">.</span>title <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Now with live updating!&#34;</span>
doc<span style="color:#f92672">.</span>add_root(fig)

apps <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;/&#39;</span>: Application(FunctionHandler(make_document))}

server <span style="color:#f92672">=</span> Server(apps, port<span style="color:#f92672">=</span><span style="color:#ae81ff">5001</span>)
server<span style="color:#f92672">.</span>start()</code></pre></div></li>
</ul>

<h3 id="real-example-dask-s-dashboard">Real example - Dask&rsquo;s dashboard</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">make_document</span>(doc):
    source <span style="color:#f92672">=</span> ColumnDataSource({<span style="color:#e6db74">&#39;time&#39;</span>: [time(), time() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>],
                               <span style="color:#e6db74">&#39;idle&#39;</span>: [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.1</span>],
                               <span style="color:#e6db74">&#39;saturated&#39;</span>: [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.1</span>]})

    x_range <span style="color:#f92672">=</span> DataRange1d(follow<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;end&#39;</span>, follow_interval<span style="color:#f92672">=</span><span style="color:#ae81ff">20000</span>, range_padding<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

    fig <span style="color:#f92672">=</span> figure(title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Idle and Saturated Workers Over Time&#34;</span>,
                 x_axis_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;datetime&#39;</span>, y_range<span style="color:#f92672">=</span>[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>, len(scheduler<span style="color:#f92672">.</span>workers) <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.1</span>],
                 height<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, tools<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>, x_range<span style="color:#f92672">=</span>x_range, <span style="color:#f92672">**</span>kwargs)
    fig<span style="color:#f92672">.</span>line(source<span style="color:#f92672">=</span>source, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;time&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;idle&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>)
    fig<span style="color:#f92672">.</span>line(source<span style="color:#f92672">=</span>source, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;time&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;saturated&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;green&#39;</span>)
    fig<span style="color:#f92672">.</span>yaxis<span style="color:#f92672">.</span>minor_tick_line_color <span style="color:#f92672">=</span> None

    fig<span style="color:#f92672">.</span>add_tools(
        ResetTool(reset_size<span style="color:#f92672">=</span>False),
        PanTool(dimensions<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;width&#34;</span>),
        WheelZoomTool(dimensions<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;width&#34;</span>)
    )

    doc<span style="color:#f92672">.</span>add_root(fig)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update</span>():
        result <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;time&#39;</span>: [time() <span style="color:#f92672">*</span> <span style="color:#ae81ff">1000</span>],
                  <span style="color:#e6db74">&#39;idle&#39;</span>: [len(scheduler<span style="color:#f92672">.</span>idle)],
                  <span style="color:#e6db74">&#39;saturated&#39;</span>: [len(scheduler<span style="color:#f92672">.</span>saturated)]}
        source<span style="color:#f92672">.</span>stream(result, <span style="color:#ae81ff">10000</span>)

    doc<span style="color:#f92672">.</span>add_periodic_callback(update, <span style="color:#ae81ff">100</span>)</code></pre></div>
<h2 id="streaming-dataframes">Streaming Dataframes</h2>

<ul>
<li><p><a href="http://matthewrocklin.com/blog/work/2017/10/16/streaming-dataframes-1">Article</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> streamz.dataframe <span style="color:#f92672">import</span> Random

sdf <span style="color:#f92672">=</span> Random(freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;1ms&#39;</span>, interval<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;100ms&#39;</span>)</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"></code></pre></div></li>
</ul>
</div>

        
        <div class="section bottom-menu">
<hr />
<p>


    

    
        
            <a href="/code">
                code
            </a>
        
    
    
        
            &#183; 
            <a href="https://tiny.cc/oceannotebook">
                notebook
            </a>
        
            &#183; 
            <a href="https://github.com/Oceanbao/KEN">
                KEN
            </a>
        
            &#183; 
            <a href="/prose">
                prose
            </a>
        
            &#183; 
            <a href="/gallery">
                gallery
            </a>
        
            &#183; 
            <a href="/qui">
                qui et quoi?
            </a>
        
    
    &#183; 
    <a href="https://oceanbao.github.io/">
        main
    </a>

</p></div>
        

        <div class="section footer">Ocean Ode

<script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script></div>
    </div>
</body>

</html>